import streamlit as st
import pandas as pd
from datetime import datetime, timezone, timedelta
import io
import base64
from news_collector import NewsCollector
from naver_search import NaverNewsSearcher
import google.generativeai as genai
from typing import List, Dict
import json
import requests
from bs4 import BeautifulSoup
from stock_market import display_stock_market_tab, get_ticker_from_name, display_trading_value
from pykrx import stock
import time
import plotly.graph_objects as go
import numpy as np
import os
import FinanceDataReader as fdr
from streamlit_option_menu import option_menu
import re
from stock_news import display_stock_news_results
from download_utils import DownloadManager
from util.ai.ai_utils import AIManager
from util.data_collector import DataCollector

# ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
ai_manager = AIManager()
download_manager = DownloadManager()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê²½ì œì  ììœ  í”„ë¡œì íŠ¸",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'newspaper_articles' not in st.session_state:
    st.session_state['newspaper_articles'] = None
if 'paper_date' not in st.session_state:
    st.session_state['paper_date'] = None
if 'search_articles' not in st.session_state:
    st.session_state['search_articles'] = None
if 'current_search_keyword' not in st.session_state:
    st.session_state['current_search_keyword'] = None
if 'filtered_articles' not in st.session_state:
    st.session_state['filtered_articles'] = None
if 'ai_report' not in st.session_state:
    st.session_state['ai_report'] = None
if 'stock_data' not in st.session_state:
    st.session_state['stock_data'] = None
if 'stock_date' not in st.session_state:
    st.session_state['stock_date'] = None
if 'stock_filtered_data' not in st.session_state:
    st.session_state['stock_filtered_data'] = None
if 'stock_news_data' not in st.session_state:
    st.session_state['stock_news_data'] = None
if 'stock_news_filtered_data' not in st.session_state:
    st.session_state['stock_news_filtered_data'] = None
if 'stock_news_date' not in st.session_state:
    st.session_state['stock_news_date'] = None
if 'stock_news_keywords' not in st.session_state:
    st.session_state['stock_news_keywords'] = None
if 'stock_news_keyword_counts' not in st.session_state:
    st.session_state['stock_news_keyword_counts'] = {}
if 'stock_news_matched_stocks' not in st.session_state:
    st.session_state['stock_news_matched_stocks'] = set()
if 'market_data' not in st.session_state:
    st.session_state['market_data'] = None
if 'market_date' not in st.session_state:
    st.session_state['market_date'] = None
if 'market_start_date' not in st.session_state:
    # í•œêµ­ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ëŠ˜ ë‚ ì§œ ì„¤ì •
    KST = timezone(timedelta(hours=9))
    today = datetime.now(KST).date()
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ë¡œ ì„¤ì •
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    st.session_state['market_start_date'] = today - timedelta(days=90)  # 90ì¼ ì „
if 'market_end_date' not in st.session_state:
    # í•œêµ­ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ëŠ˜ ë‚ ì§œ ì„¤ì •
    KST = timezone(timedelta(hours=9))
    today = datetime.now(KST).date()
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ë¡œ ì„¤ì •
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    st.session_state['market_end_date'] = today

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .category-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #333;
        margin: 1rem 0 0.5rem 0;
        background-color: #f0f2f6;
        padding: 0.5rem;
        border-radius: 5px;
    }
    .article-item {
        background-color: #f8f9fa;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
        border-left: 4px solid #1f77b4;
    }
    .search-box {
        background-color: #e9ecef;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .newspaper-section {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .stButton > button {
        width: 100%;
    }
    .ai-report {
        background-color: #f8f9fa;
        padding: 2rem;
        margin: 1rem 0;
        border-radius: 10px;
        border: 1px solid #e9ecef;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .ai-report h3 {
        color: #1f77b4;
        margin-bottom: 1.5rem;
    }
    .ai-report p {
        line-height: 1.6;
        margin-bottom: 1rem;
    }
    .ai-report ul {
        margin-left: 1.5rem;
        margin-bottom: 1rem;
    }
    .ai-report li {
        margin-bottom: 0.5rem;
    }
    /* ì‚¬ì´ë“œë°” ë©”ë‰´ ìŠ¤íƒ€ì¼ë§ */
    .css-1d391kg {
        padding: 0.5rem 0;
    }
    .css-1d391kg .stRadio > div {
        padding: 0.5rem 1rem;
    }
    .css-1d391kg .stRadio > div:hover {
        background-color: #f0f2f6;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)

def check_secrets():
    """secrets ì„¤ì • í™•ì¸ - í™”ë©´ì— ë…¸ì¶œí•˜ì§€ ì•ŠìŒ"""
    missing_secrets = []
    api_available = False
    
    try:
        client_id = st.secrets["naver_api"]["client_id"]
        client_secret = st.secrets["naver_api"]["client_secret"]
        if client_id and client_secret:
            api_available = True
    except KeyError:
        missing_secrets.append("ë„¤ì´ë²„ API í‚¤")
    
    return api_available, missing_secrets

def remove_duplicates(articles):
    """ì¤‘ë³µ ê¸°ì‚¬ ì œê±°"""
    seen_urls = set()
    unique_articles = []
    
    for article in articles:
        if article['url'] not in seen_urls:
            seen_urls.add(article['url'])
            unique_articles.append(article)
    
    return unique_articles

def newspaper_collection_tab():
    st.markdown("### ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘")
    st.markdown("ì¢…ì´ ì‹ ë¬¸ì— ì‹¤ì œë¡œ ì‹¤ë¦° ê¸°ì‚¬ë§Œ ìˆ˜ì§‘í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")
    
    # ë‚ ì§œ ì„ íƒì„ ë§¨ ìœ„ë¡œ ì´ë™
    KST = timezone(timedelta(hours=9))
    current_date = datetime.now(KST).date()
    
    selected_date = st.date_input(
        "ğŸ“… ìˆ˜ì§‘í•  ë‚ ì§œ ì„ íƒ",
        value=current_date,
        max_value=current_date,
        help="ìˆ˜ì§‘í•˜ê³  ì‹¶ì€ ì‹ ë¬¸ ë°œí–‰ì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        key="date_picker"
    )
    
    st.markdown("---")
    
    # ì‹ ë¬¸ì‚¬ ì„ íƒ ì„¹ì…˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown('<div class="category-header">ğŸ“Š ê²½ì œ ì‹ ë¬¸</div>', unsafe_allow_html=True)
        with st.container():
            economic_papers = {
                "ë§¤ì¼ê²½ì œ": "009",
                "ë¨¸ë‹ˆíˆ¬ë°ì´": "008", 
                "ì„œìš¸ê²½ì œ": "011",
                "ì´ë°ì¼ë¦¬": "018",
                "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": "014",
                "í•œêµ­ê²½ì œ": "015"
            }
            
            economic_all = st.checkbox("ì „ì²´ ì„ íƒ", key="economic_all")
            economic_selected = []
            
            for paper, oid in economic_papers.items():
                checked = st.checkbox(paper, value=economic_all, key=f"economic_{oid}")
                if checked:
                    economic_selected.append((paper, oid))
    
    with col2:
        st.markdown('<div class="category-header">ğŸ“‹ ì¢…í•©ì¼ê°„ì§€(ì¡°ê°„)</div>', unsafe_allow_html=True)
        with st.container():
            general_papers = {
                "ê²½í–¥ì‹ ë¬¸": "032",
                "êµ­ë¯¼ì¼ë³´": "005",
                "ë™ì•„ì¼ë³´": "020",
                "ì„œìš¸ì‹ ë¬¸": "081",
                "ì„¸ê³„ì¼ë³´": "022",
                "ì¡°ì„ ì¼ë³´": "023",
                "ì¤‘ì•™ì¼ë³´": "025",
                "í•œê²¨ë ˆ": "028",
                "í•œêµ­ì¼ë³´": "469",
                "ë””ì§€í„¸íƒ€ì„ìŠ¤": "029",
                "ì „ìì‹ ë¬¸": "030"
            }
            
            general_all = st.checkbox("ì „ì²´ ì„ íƒ", key="general_all")
            general_selected = []
            
            for paper, oid in general_papers.items():
                checked = st.checkbox(paper, value=general_all, key=f"general_{oid}")
                if checked:
                    general_selected.append((paper, oid))
    
    with col3:
        st.markdown('<div class="category-header">ğŸŒ† ì„ê°„ ì‹ ë¬¸</div>', unsafe_allow_html=True)
        with st.container():
            evening_papers = {
                "ë¬¸í™”ì¼ë³´": "021",
                "í—¤ëŸ´ë“œê²½ì œ": "016", 
                "ì•„ì‹œì•„ê²½ì œ": "277"
            }
            
            evening_all = st.checkbox("ì „ì²´ ì„ íƒ", key="evening_all")
            evening_selected = []
            
            for paper, oid in evening_papers.items():
                checked = st.checkbox(paper, value=evening_all, key=f"evening_{oid}")
                if checked:
                    evening_selected.append((paper, oid))
    
    st.markdown("---")
    
    # í¬ë¡¤ë§ ì‹œì‘ ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", type="primary", use_container_width=True, key="btn_start_crawling"):
            all_selected = economic_selected + general_selected + evening_selected
            
            if not all_selected:
                st.error("âŒ ìµœì†Œ í•˜ë‚˜ì˜ ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            collector = NewsCollector()
            
            try:
                status_text.text(f"ğŸš€ {len(all_selected)}ê°œ ì‹ ë¬¸ì‚¬ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘...")
                progress_bar.progress(20)
                
                # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥´ê²Œ ìˆ˜ì§‘ (í…Œì´ë¸” í˜•íƒœë¡œ ìƒíƒœ í‘œì‹œ)
                all_articles = collector.crawl_multiple_papers(all_selected, selected_date.strftime("%Y%m%d"))
                
                progress_bar.progress(80)
                
                # ì¤‘ë³µ ì œê±°
                unique_articles = remove_duplicates(all_articles)
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['newspaper_articles'] = unique_articles
                st.session_state['paper_date'] = selected_date
                
                status_text.text(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(unique_articles)}ê°œ ê¸°ì‚¬")
                progress_bar.progress(100)
                
                if len(unique_articles) == 0:
                    st.warning("âš ï¸ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‚ ì§œë‚˜ ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•´ë³´ì„¸ìš”.")
                else:
                    st.success(f"ğŸ‰ {len(all_selected)}ê°œ ì‹ ë¬¸ì‚¬ì—ì„œ ì´ {len(unique_articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                st.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            finally:
                collector.close()
    
    # ê²°ê³¼ í‘œì‹œ
    if 'newspaper_articles' in st.session_state:
        display_newspaper_results()

def display_newspaper_results():
    articles = st.session_state['newspaper_articles']
    paper_date = st.session_state['paper_date']
    
    st.markdown("---")
    
    # articlesê°€ Noneì´ë©´ í•¨ìˆ˜ ì¢…ë£Œ
    if articles is None:
        st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•˜ê³  í¬ë¡¤ë§ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return
    
    # ê²°ê³¼ í‘œì‹œ (ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì•„ë˜ë¡œ ì´ë™)
    if paper_date is not None:
        st.markdown(f"### ğŸ“° {paper_date.strftime('%Yë…„ %mì›” %dì¼')}ì˜ ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ")
    else:
        st.markdown("### ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ")
    
    st.markdown(f"**ì´ {len(articles)}ê°œ ê¸°ì‚¬**")
    
    if len(articles) == 0:
        st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²€ìƒ‰ ê¸°ëŠ¥ (ë²„íŠ¼ ì •ë ¬ ìˆ˜ì •)
    col1, col2, col3 = st.columns([3, 1, 1])

    with col1:
        search_term = st.text_input("ğŸ” ê¸°ì‚¬ ê²€ìƒ‰", placeholder="ì œëª©ìœ¼ë¡œ ê²€ìƒ‰...", key="input_search_articles_newspaper")

    with col2:
        # ë¼ë²¨ì„ ì¶”ê°€í•˜ì—¬ ë†’ì´ ë§ì¶¤
        st.markdown("&nbsp;", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„
        if st.button("ê²€ìƒ‰", key="btn_search_articles_newspaper", use_container_width=True):
            if search_term:
                filtered_articles = [
                    article for article in articles 
                    if search_term.lower() in article['title'].lower()
                ]
                st.session_state['filtered_articles'] = filtered_articles
            else:
                st.session_state['filtered_articles'] = articles

    with col3:
        # ë¼ë²¨ì„ ì¶”ê°€í•˜ì—¬ ë†’ì´ ë§ì¶¤
        st.markdown("&nbsp;", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„
        if st.button("ì´ˆê¸°í™”", key="btn_reset_articles_newspaper", use_container_width=True):
            st.session_state['filtered_articles'] = articles
            st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # í‘œì‹œí•  ê¸°ì‚¬ ê²°ì •
    display_articles = st.session_state.get('filtered_articles', articles)
    
    # display_articlesê°€ Noneì´ë©´ articles ì‚¬ìš©
    if display_articles is None:
        display_articles = articles
    
    # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ê²€ìƒ‰ ê¸°ëŠ¥ ì•„ë˜ë¡œ ì´ë™
    st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # ë‹¤ìš´ë¡œë“œ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        download_manager = DownloadManager()
        
        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        excel_data = download_manager.create_excel_download(display_articles)
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"newspaper_articles_{paper_date.strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
    with col2:
        # í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        text_data = download_manager.create_text_download(display_articles, paper_date)
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=text_data,
            file_name=f"newspaper_articles_{paper_date.strftime('%Y%m%d')}.txt",
            mime="text/plain"
        )
    
    with col3:
        if st.button("ğŸ“‹ í´ë¦½ë³´ë“œ ë³µì‚¬", key="btn_copy_newspaper_text"):
            copy_text = download_manager.create_text_download(display_articles, paper_date)
            st.code(copy_text, language="text")
            st.success("âœ… í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë³µì‚¬í•˜ì„¸ìš”.")
    
    with col4:
        if st.button("ğŸ¤– AI ë³´ê³ ì„œ ìƒì„±", key="btn_generate_ai_report"):
            with st.spinner("AIê°€ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ê³  ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                # AIManager ì‚¬ìš©
                report_text = AIManager.generate_ai_report(display_articles, paper_date)
                st.session_state['ai_report'] = report_text
                st.success("âœ… AI ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
    
    st.markdown("---")
    
    # AI ë³´ê³ ì„œê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if 'ai_report' in st.session_state and st.session_state['ai_report'] is not None:
        st.markdown("### ğŸ“Š AI ìš”ì•½ ë³´ê³ ì„œ")
        st.markdown(st.session_state['ai_report'])
        st.download_button(
            label="ğŸ“‘ AI ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=st.session_state['ai_report'],
            file_name=f"ai_report_{paper_date.strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_ai_report"
        )
        st.markdown("---")
    
    # ì‹ ë¬¸ì‚¬ë³„ë¡œ ê·¸ë£¹í™”
    newspaper_groups = {}
    for article in display_articles:
        newspaper = article['newspaper']
        if newspaper not in newspaper_groups:
            newspaper_groups[newspaper] = []
        newspaper_groups[newspaper].append(article)
    
    # ì‹ ë¬¸ì‚¬ë³„ ê¸°ì‚¬ í‘œì‹œ
    for newspaper, articles_list in newspaper_groups.items():
        st.markdown(f"#### ğŸ“Œ [{newspaper}] ({len(articles_list)}ê°œ)")
        for article in articles_list:
            page_info = f"[{article['page']}] " if article['page'] else ""
            st.markdown(f"ğŸ”¹ {page_info}[{article['title']}]({article['url']})")

def naver_search_tab():
    st.markdown("### ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰")
    st.markdown("ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì´ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        keyword = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="input_search_keyword")
    
    with col2:
        # selectboxë¥¼ number_inputìœ¼ë¡œ ë³€ê²½
        max_articles = st.number_input(
            "ìµœëŒ€ ê¸°ì‚¬ ìˆ˜", 
            min_value=1, 
            max_value=1000, 
            value=100, 
            step=1, 
            key="input_max_articles",
            help="1ë¶€í„° 1000ê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        )
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True, key="btn_start_search"):
            if not keyword:
                st.error("âŒ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            searcher = NaverNewsSearcher()
            
            try:
                status_text.text("ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
                progress_bar.progress(50)
                
                articles = searcher.search_news(keyword, max_articles)
                
                progress_bar.progress(100)
                status_text.text(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! ì´ {len(articles)}ê°œ ê¸°ì‚¬")
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['search_articles'] = articles
                st.session_state['current_search_keyword'] = keyword
                
                if len(articles) == 0:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                else:
                    st.success(f"ğŸ‰ '{keyword}'ì— ëŒ€í•œ {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                progress_bar.progress(0)
                status_text.text("")
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if 'search_articles' in st.session_state:
        display_search_results()

def display_search_results():
    articles = st.session_state['search_articles']
    keyword = st.session_state['current_search_keyword']
    
    st.markdown("---")
    
    # articlesê°€ Noneì´ë©´ í•¨ìˆ˜ ì¢…ë£Œ
    if articles is None:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return
        
    st.markdown(f"### ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(articles)}ê°œ)")
    
    if len(articles) == 0:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ìƒë‹¨ìœ¼ë¡œ ì´ë™
    st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        excel_data = download_manager.create_search_excel_download(articles)
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="btn_download_naver_search_excel"
        )
    
    with col2:
        csv_data = download_manager.create_search_csv_download(articles)
        st.download_button(
            label="ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            key="btn_download_naver_search_csv"
        )
    
    with col3:
        text_data = download_manager.create_search_text_download(articles, keyword)
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=text_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_naver_search_text"
        )
    
    st.markdown("---")
    
    # ê²°ê³¼ í‘œì‹œ ì˜µì…˜
    display_mode = st.radio("í‘œì‹œ ë°©ì‹", ["ìš”ì•½ ë³´ê¸°", "ì „ì²´ ë³´ê¸°"], horizontal=True, key="radio_display_mode")
    
    if display_mode == "ìš”ì•½ ë³´ê¸°":
        # ê°„ë‹¨í•œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
        for i, article in enumerate(articles, 1):
            st.markdown(f"**{i}.** [{article['title']}]({article['link']})")
            st.caption(f"ğŸ“… {article['pubDate']} | ğŸ“° {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            if article.get('description'):
                st.write(f"ğŸ’¬ {article['description'][:100]}...")
            st.markdown("---")
    else:
        # ìƒì„¸í•œ expander í˜•íƒœë¡œ í‘œì‹œ
        for i, article in enumerate(articles, 1):
            with st.expander(f"{i}. {article['title']}", expanded=False):
                st.markdown(f"**ìš”ì•½:** {article['description']}")
                st.markdown(f"**ë°œí–‰ì¼:** {article['pubDate']}")
                st.markdown(f"**ì¶œì²˜:** {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                st.markdown(f"**ë§í¬:** [ê¸°ì‚¬ ë³´ê¸°]({article['link']})")

def display_market_analysis(df: pd.DataFrame, date: datetime):
    """ì‹œì¥ ë°ì´í„° ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    # í˜„ì¬ ì‹œê°„ í‘œì‹œ
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.success(f"âœ… {len(df)}ê°œ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤! (ìµœì¢… ì—…ë°ì´íŠ¸: {current_time})")
    
    # ìš”ì•½ ì •ë³´
    st.markdown("### ğŸ“Š ì‹œì¥ ìš”ì•½")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ì¢…ëª© ìˆ˜", f"{len(df):,}ê°œ")
    with col2:
        avg_trading_value = df['ê±°ë˜ëŒ€ê¸ˆ'].mean()
        st.metric("í‰ê·  ê±°ë˜ëŒ€ê¸ˆ", f"{avg_trading_value/100000000:.0f}ì–µì›")
    with col3:
        st.metric("í‰ê·  ì‹œê°€ì´ì•¡", f"{df['ì‹œê°€ì´ì•¡'].mean()/100000000:.0f}ì–µì›")
    with col4:
        st.metric("í‰ê·  ë“±ë½ë¥ ", f"{df['ë“±ë½ë¥ '].mean():.2f}%")
    
    # ë“±ë½ë¥  ë¶„í¬ ì°¨íŠ¸
    st.markdown("### ğŸ“ˆ ë“±ë½ë¥  ë¶„í¬")
    fig = go.Figure(data=[go.Histogram(x=df['ë“±ë½ë¥ '], nbinsx=50)])
    fig.update_layout(
        title="ë“±ë½ë¥  ë¶„í¬ë„",
        xaxis_title="ë“±ë½ë¥  (%)",
        yaxis_title="ì¢…ëª© ìˆ˜"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ì‹œì¥ë³„ ì¢…ëª© ìˆ˜
    market_counts = df['ì‹œì¥êµ¬ë¶„'].value_counts()
    fig = go.Figure(data=[go.Pie(
        labels=market_counts.index,
        values=market_counts.values,
        hole=.3
    )])
    fig.update_layout(title="ì‹œì¥ë³„ ì¢…ëª© ë¶„í¬")
    st.plotly_chart(fig, use_container_width=True)
    
    # ìƒì„¸ ë°ì´í„° í‘œì‹œ
    st.markdown("### ğŸ“‹ ì¢…ëª© ìƒì„¸ ì •ë³´")
    
    # ì •ë ¬ ì˜µì…˜
    sort_column = st.selectbox(
        "ì •ë ¬ ê¸°ì¤€",
        options=['ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ë“±ë½ë¥ ', 'ì‹œê°€ì´ì•¡', 'ë³€ë™í­', 'PER', 'PBR', 'EPS', 'BPS', 'DIV', 'DPS'],
        index=3
    )
    
    df = df.sort_values(by=sort_column, ascending=False)
    
    # ë°ì´í„° í¬ë§·íŒ…
    display_df = df.copy()
    display_df['ì‹œê°€ì´ì•¡'] = display_df['ì‹œê°€ì´ì•¡'].apply(lambda x: f"{x/100000000:.0f}ì–µì›")
    display_df['ê±°ë˜ëŒ€ê¸ˆ'] = display_df['ê±°ë˜ëŒ€ê¸ˆ'].apply(lambda x: f"{x/100000000:.0f}ì–µì›")
    display_df['ê±°ë˜ëŸ‰'] = display_df['ê±°ë˜ëŸ‰'].apply(lambda x: f"{x:,}")
    display_df['ë³€ë™í­'] = display_df['ë³€ë™í­'].apply(lambda x: f"{x:,}")
    display_df['ë“±ë½ë¥ '] = display_df['ë“±ë½ë¥ '].apply(lambda x: f"{x:.2f}%")
    
    # ê¸°ë³¸ ì§€í‘œ í¬ë§·íŒ…
    for col in ['PER', 'PBR', 'EPS', 'BPS', 'DIV', 'DPS']:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(lambda x: f"{x:.2f}" if pd.notnull(x) else "-")
    
    # í‘œì‹œí•  ì—´ ì„ íƒ
    columns_to_display = [
        'ì¢…ëª©ëª…', 'ì‹œì¥êµ¬ë¶„', 'ì—…ì¢…', 'ì£¼ìš”ì œí’ˆ', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€', 
        'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ', 'ë“±ë½ë¥ ', 'ë³€ë™í­', 'ì‹œê°€ì´ì•¡',
        'PER', 'PBR', 'EPS', 'BPS', 'DIV', 'DPS'
    ]
    
    # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
    st.dataframe(
        display_df[columns_to_display],
        use_container_width=True,
        hide_index=True
    )
    
    # CSV ë‹¤ìš´ë¡œë“œ
    csv_data = download_manager.create_stock_data_download(df[columns_to_display], date)
    st.download_button(
        label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_data,
        file_name=f"stock_data_{date.strftime('%Y%m%d')}.csv",
        mime="text/csv"
    )
    
    # ì§€í‘œ ì„¤ëª…
    st.markdown("### ğŸ“Š ì£¼ìš” ì§€í‘œ ì„¤ëª…")
    st.markdown("""
    - **PER (ì£¼ê°€ìˆ˜ìµë¹„ìœ¨)**: ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœì´ìµ(EPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ê¸°ì—…ì˜ ìˆ˜ìµì„±ê³¼ ì£¼ê°€ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì €í‰ê°€ëœ ì£¼ì‹ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **PBR (ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨)**: ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœìì‚°(BPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ê¸°ì—…ì˜ ìˆœìì‚° ëŒ€ë¹„ ì£¼ê°€ì˜ ìˆ˜ì¤€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 1 ë¯¸ë§Œì´ë©´ ìˆœìì‚°ë³´ë‹¤ ì €í‰ê°€ëœ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **EPS (ì£¼ë‹¹ìˆœì´ìµ)**: ê¸°ì—…ì˜ ìˆœì´ìµì„ ë°œí–‰ì£¼ì‹ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ì£¼ì£¼ê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ì´ìµì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    - **BPS (ì£¼ë‹¹ìˆœìì‚°)**: ê¸°ì—…ì˜ ìˆœìì‚°ì„ ë°œí–‰ì£¼ì‹ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ì£¼ì£¼ê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ìˆœìì‚°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    - **DIV (ë°°ë‹¹ìˆ˜ìµë¥ )**: ì£¼ë‹¹ë°°ë‹¹ê¸ˆ(DPS)ì„ ì£¼ê°€ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, íˆ¬ìê¸ˆì•¡ ëŒ€ë¹„ ë°°ë‹¹ìˆ˜ìµì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    - **DPS (ì£¼ë‹¹ë°°ë‹¹ê¸ˆ)**: ê¸°ì—…ì´ ì£¼ì£¼ì—ê²Œ ì§€ê¸‰í•˜ëŠ” ë°°ë‹¹ê¸ˆì„ ë°œí–‰ì£¼ì‹ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤.
    """)

def display_stock_data():
    """ì „ì²´ ì¢…ëª© ì‹œì„¸ ì¡°íšŒ"""
    st.markdown("### ğŸ“Š ì „ì²´ ì¢…ëª© ì‹œì„¸ ì¡°íšŒ")
    
    # ë‚ ì§œ ì„ íƒ
    today = datetime.now()
    max_date = today.strftime("%Y%m%d")
    
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    
    # ë‚ ì§œ ì„ íƒ ìœ„ì ¯
    selected_date = st.date_input(
        "ì¡°íšŒ ë‚ ì§œ",
        value=today,
        max_value=today,
        help="ì¡°íšŒí•  ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # í•„í„°ë§ ì˜µì…˜
    col1, col2, col3 = st.columns([2, 5, 1])
    
    with col1:
        market_filter = st.multiselect(
            "ì‹œì¥ ì„ íƒ",
            options=['KOSPI', 'KOSDAQ'],
            default=['KOSPI', 'KOSDAQ']
        )
    
    with col2:
        st.markdown("ì£¼ê°€ ë²”ìœ„")
        price_col1, price_col2 = st.columns(2)
        with price_col1:
            min_price = st.number_input(
                "ìµœì†Œ ì£¼ê°€",
                min_value=0,
                max_value=1500000,
                value=0,
                step=1000,
                help="ìµœì†Œ ì£¼ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
        with price_col2:
            max_price = st.number_input(
                "ìµœëŒ€ ì£¼ê°€",
                min_value=0,
                max_value=1500000,
                value=1500000,
                step=1000,
                help="ìµœëŒ€ ì£¼ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
        
        # ìŠ¬ë¼ì´ë”ëŠ” ì…ë ¥ëœ ê°’ê³¼ ë™ê¸°í™”
        price_range = st.slider(
            "",
            min_value=0,
            max_value=1500000,
            value=(min_price, max_price),
            step=1000,
            help="ì›í•˜ëŠ” ì£¼ê°€ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col3:
        volume_filter = st.number_input(
            "ìµœì†Œ ê±°ë˜ëŸ‰",
            min_value=0,
            value=0,
            step=1000
        )
    
    # ë°ì´í„° ì¡°íšŒ ë²„íŠ¼
    if st.button("ğŸ” ë°ì´í„° ì¡°íšŒ", type="primary"):
        with st.spinner('ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                # KOSPI ë°ì´í„° ìˆ˜ì§‘
                kospi_df = DataCollector.collect_market_data("KOSPI", selected_date.strftime("%Y%m%d"))
                time.sleep(1)  # API í˜¸ì¶œ ê°„ ë”œë ˆì´
                
                # KOSDAQ ë°ì´í„° ìˆ˜ì§‘
                kosdaq_df = DataCollector.collect_market_data("KOSDAQ", selected_date.strftime("%Y%m%d"))
                
                # ë°ì´í„° í•©ì¹˜ê¸°
                df = pd.concat([kospi_df, kosdaq_df])
                
                # í•„í„°ë§
                filtered_df = DataCollector.filter_market_data(
                    df,
                    market_filter,
                    (price_range[0], price_range[1]),
                    volume_filter
                )
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['stock_data'] = df
                st.session_state['stock_filtered_data'] = filtered_df
                st.session_state['stock_date'] = selected_date
                
                if len(filtered_df) > 0:
                    display_market_analysis(filtered_df, selected_date)
                else:
                    st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    else:
        # ì €ì¥ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state['stock_filtered_data'] is not None:
            display_market_analysis(st.session_state['stock_filtered_data'], st.session_state['stock_date'])

def extract_stock_names(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¢…ëª©ëª… ì¶”ì¶œ"""
    # ì¢…ëª©ëª… íŒ¨í„´ (í•œê¸€ 2-10ì)
    pattern = r'[ê°€-í£]{2,10}(?:ì£¼ì‹|ì¦ê¶Œ|ê¸°ì—…|íšŒì‚¬|ì£¼)'
    matches = re.findall(pattern, text)
    return [match.replace('ì£¼ì‹', '').replace('ì¦ê¶Œ', '').replace('ê¸°ì—…', '').replace('íšŒì‚¬', '').replace('ì£¼', '') for match in matches]

def search_stock_news(keywords, start_date, end_date, max_articles):
    """íŠ¹ì§•ì£¼ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰"""
    searcher = NaverNewsSearcher()
    return searcher.search_stock_news(keywords, start_date, max_articles)

def display_stock_news_tab():
    """íŠ¹ì§•ì£¼ í¬ì°© íƒ­ í‘œì‹œ"""
    st.markdown("### ğŸ” íŠ¹ì§•ì£¼ í¬ì°©")
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ëª©ë¡
    default_keywords = ["íŠ¹ì§•ì£¼", "ê¸‰ë“±ì£¼", "ìƒí•œê°€", "í•˜í•œê°€", "ê¸‰ë“±ì„¸", "ê¸‰ë½ì„¸", 
                       "ê°•ì„¸", "ì•½ì„¸", "ê±°ë˜ëŸ‰ ì¦ê°€", "ì‹ ê³ ê°€", "ì‹ ì €ê°€"]
    
    # ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ ì…ë ¥
    custom_keyword = st.text_input(
        "ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥",
        help="ì›í•˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì…ë ¥ í›„ Enterë¥¼ ëˆ„ë¥´ë©´ í‚¤ì›Œë“œê°€ ì¶”ê°€ë©ë‹ˆë‹¤."
    )
    
    # ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ë©´ default_keywordsì— ì¶”ê°€
    if custom_keyword and custom_keyword not in default_keywords:
        default_keywords.append(custom_keyword)
    
    # í‚¤ì›Œë“œ ì„ íƒ (ê¸°ë³¸ í‚¤ì›Œë“œ + ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ)
    selected_keywords = st.multiselect(
        "ê²€ìƒ‰ í‚¤ì›Œë“œ ì„ íƒ",
        options=default_keywords,
        default=default_keywords[:3]
    )
    
    # ì¡°íšŒ ë‚ ì§œ ì„ íƒ
    today = datetime.now()
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    
    selected_date = st.date_input(
        "ì¡°íšŒ ë‚ ì§œ",
        value=today,
        max_value=today,
        help="ì¡°íšŒí•  ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì…ë ¥
    max_articles = st.number_input(
        "ìµœëŒ€ ê¸°ì‚¬ ìˆ˜(1000ê°œ ì´í•˜)",
        min_value=10,
        max_value=1000,
        value=100,
        step=10
    )
    
    if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary"):
        with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
            # 1. ë‰´ìŠ¤ ê²€ìƒ‰
            articles = search_stock_news(selected_keywords, selected_date, None, max_articles)
            
            # í‚¤ì›Œë“œë³„ ê¸°ì‚¬ ìˆ˜ ê³„ì‚°
            keyword_article_counts = {}
            for keyword in selected_keywords:
                count = sum(1 for article in articles if keyword in article['title'] or keyword in article['description'])
                keyword_article_counts[keyword] = count
            
            # 2. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒí•œ ë‚ ì§œ ê¸°ì¤€)
            market_data = {}
            all_stock_names = set()  # ëª¨ë“  ì¢…ëª©ëª…ì„ ì €ì¥í•  set
            
            for market in ['KOSPI', 'KOSDAQ']:
                try:
                    df = DataCollector.collect_market_data(market, selected_date.strftime("%Y%m%d"))
                    market_data[market] = df
                    # ì‹œì¥ ë°ì´í„°ì—ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
                    all_stock_names.update(df['ì¢…ëª©ëª…'].tolist())
                except Exception as e:
                    st.error(f"{market} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # 3. ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¢…ëª©ëª… ë§¤ì¹­
            stock_articles = {}  # ì¢…ëª©ë³„ ê¸°ì‚¬ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            stock_keywords = {}  # ì¢…ëª©ë³„ ë§¤ì¹­ëœ í‚¤ì›Œë“œë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            matched_stocks = set()  # ë§¤ì¹­ëœ ì¢…ëª©ì„ ì¶”ì í•˜ê¸° ìœ„í•œ set
            
            for article in articles:
                # ê¸°ì‚¬ ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ì¢…ëª©ëª… ì°¾ê¸°
                text = article['title'] + " " + article['description']
                
                # ê¸°ì‚¬ì— í¬í•¨ëœ í‚¤ì›Œë“œ ì°¾ê¸°
                matched_keywords = [keyword for keyword in selected_keywords if keyword in text]
                
                # ì‹œì¥ ë°ì´í„°ì˜ ëª¨ë“  ì¢…ëª©ëª…ê³¼ ë§¤ì¹­
                for stock_name in all_stock_names:
                    if stock_name in text:
                        if stock_name not in stock_articles:
                            stock_articles[stock_name] = []
                            stock_keywords[stock_name] = set()
                        stock_articles[stock_name].append(article)
                        stock_keywords[stock_name].update(matched_keywords)
                        matched_stocks.add(stock_name)
            
            # 4. ê²°ê³¼ ìƒì„±
            results = []
            for stock_name, articles in stock_articles.items():
                # í•´ë‹¹ ì¢…ëª©ì˜ ì‹œì¥ ë°ì´í„° ì°¾ê¸°
                for market, df in market_data.items():
                    stock_data = df[df['ì¢…ëª©ëª…'] == stock_name]
                    if not stock_data.empty:
                        stock = stock_data.iloc[0]
                        
                        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
                        result = {
                            'ì¢…ëª©ëª…': stock['ì¢…ëª©ëª…'],
                            'ì‹œì¥êµ¬ë¶„': market,
                            'ì—…ì¢…': stock['ì—…ì¢…'],
                            'ì£¼ìš”ì œí’ˆ': stock['ì£¼ìš”ì œí’ˆ'],
                            'í˜„ì¬ê°€': stock['ì¢…ê°€'],
                            'ë“±ë½ë¥ ': stock['ë“±ë½ë¥ '],
                            'ê±°ë˜ëŸ‰': stock['ê±°ë˜ëŸ‰'],
                            'ì‹œê°€ì´ì•¡': stock['ì‹œê°€ì´ì•¡'],
                            'ê´€ë ¨ê¸°ì‚¬ìˆ˜': len(articles),
                            'ë§¤ì¹­í‚¤ì›Œë“œ': ', '.join(sorted(stock_keywords[stock_name]))
                        }
                        
                        # ê¸°ì‚¬ ì •ë³´ ì¶”ê°€ (ìµœëŒ€ 3ê°œ)
                        for i, article in enumerate(articles[:3], 1):
                            result.update({
                                f'ê¸°ì‚¬ì œëª©{i}': article['title'],
                                f'ê¸°ì‚¬ìš”ì•½{i}': article['description'],
                                f'ê¸°ì‚¬ë§í¬{i}': article['link']
                            })
                        
                        results.append(result)
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state['stock_news_data'] = results
            st.session_state['stock_news_filtered_data'] = results
            st.session_state['stock_news_date'] = selected_date
            st.session_state['stock_news_keywords'] = selected_keywords
            st.session_state['stock_news_keyword_counts'] = keyword_article_counts
            st.session_state['stock_news_matched_stocks'] = set(matched_stocks)
            
            # ê²°ê³¼ í‘œì‹œ
            display_stock_news_results(results, selected_keywords, keyword_article_counts, matched_stocks, selected_date)
    else:
        # ì €ì¥ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state['stock_news_data'] is not None:
            display_stock_news_results(
                st.session_state['stock_news_data'],
                st.session_state['stock_news_keywords'],
                st.session_state['stock_news_keyword_counts'],
                set(st.session_state['stock_news_matched_stocks']),
                st.session_state['stock_news_date']
            )

# secrets í™•ì¸ (ë³´ì•ˆ)
api_available, missing_secrets = check_secrets()

if missing_secrets:
    st.sidebar.warning(f"âš ï¸ ì„¤ì •ë˜ì§€ ì•Šì€ í•­ëª©: {', '.join(missing_secrets)}")
    st.sidebar.info("ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

st.markdown('<h1 class="main-header">ğŸ“° ê²½ì œì  ììœ  í”„ë¡œì íŠ¸ </h1>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ë©”ë‰´
with st.sidebar:
    selected = option_menu(
        menu_title="ë©”ë‰´",
        options=[
            "ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘",
            "ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰",
            "ì˜¤ëŠ˜ì˜ ì¦ì‹œ",
            "ì „ì²´ ì¢…ëª© ì‹œì„¸",
            "íŠ¹ì§•ì£¼ í¬ì°©"
        ],
        icons=[
            "newspaper",
            "search",
            "graph-up",
            "bar-chart",
            "bullseye"  # targetì„ bullseyeë¡œ ë³€ê²½
        ],
        menu_icon="list",
        default_index=0,
        styles={
            "container": {"padding": "0!important", "background-color": "transparent"},
            "icon": {"color": "black", "font-size": "16px"},
            "nav-link": {
                "font-size": "16px",
                "text-align": "left",
                "margin": "0px",
                "padding": "10px",
                "color": "black",
                "background-color": "transparent",
                "border": "none",
                "border-radius": "0px",
            },
            "nav-link-selected": {
                "background-color": "#4CAF50",
                "color": "white",
                "font-weight": "bold",
            },
        }
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“– ì‚¬ìš©ë²•")
    st.markdown("""
    **ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘:**
    1. ì›í•˜ëŠ” ì‹ ë¬¸ì‚¬ ì„ íƒ
    2. ë‚ ì§œ ì„ íƒ
    3. í¬ë¡¤ë§ ì‹œì‘
    4. AI ìš”ì•½ ë³´ê³ ì„œ ì‘ì„±(gemini)
    
    **ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰:**
    1. í‚¤ì›Œë“œ ì…ë ¥
    2. ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì„ íƒ
    3. ê²€ìƒ‰ ì‹œì‘
        
    **ì˜¤ëŠ˜ì˜ ì¦ì‹œ:**
    1. ì£¼ìš” ì§€ìˆ˜ ë™í–¥ 
    2. í™˜ìœ¨ ë° ì›ìì¬ ë™í–¥ 
    3. ê°œë³„ ì¢…ëª© ì°¨íŠ¸ ê²€ìƒ‰ 
    4. ì¢…ëª© ê¸°ìˆ ì  ì§€í‘œ ê²€ìƒ‰
                
    **íŠ¹ì§•ì£¼ í¬ì°©:**
    1. í‚¤ì›Œë“œ ì…ë ¥
    2. ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì„ íƒ
    3. ê²€ìƒ‰ ì‹œì‘
    """)
    
    st.markdown("---")
    st.markdown("### âš™ï¸ ì„¤ì • ì •ë³´")
    
    # API í‚¤ ê°’ì„ ë…¸ì¶œí•˜ì§€ ì•Šê³  ìƒíƒœë§Œ í‘œì‹œ
    api_status = "âœ… ì„¤ì •ë¨" if api_available else "âŒ ë¯¸ì„¤ì •"
    st.info(f"ë„¤ì´ë²„ API: {api_status}")
    
    # ê¸°íƒ€ ì„¤ì • ì •ë³´ (ë¯¼ê°í•˜ì§€ ì•Šì€ ì •ë³´ë§Œ)
    try:
        max_articles = st.secrets["app_settings"]["max_articles_per_request"]
        st.info(f"ìµœëŒ€ ìš”ì²­ ê¸°ì‚¬ ìˆ˜: {max_articles}")
    except:
        st.info("ê¸°ë³¸ ì„¤ì • ì‚¬ìš© ì¤‘")

# ì„ íƒëœ íƒ­ì— ë”°ë¼ í•´ë‹¹ í•¨ìˆ˜ ì‹¤í–‰
if selected == "ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘":
    newspaper_collection_tab()
elif selected == "ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰":
    naver_search_tab()
elif selected == "ì˜¤ëŠ˜ì˜ ì¦ì‹œ":
    display_stock_market_tab()
elif selected == "ì „ì²´ ì¢…ëª© ì‹œì„¸":
    display_stock_data()
elif selected == "íŠ¹ì§•ì£¼ í¬ì°©":
    display_stock_news_tab()
