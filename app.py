import streamlit as st
import pandas as pd
from datetime import datetime, timezone, timedelta
import io
import base64
from news_collector import NewsCollector
from naver_search import NaverNewsSearcher
import google.generativeai as genai
from typing import List, Dict
import json
import requests
from bs4 import BeautifulSoup
from stock_market import display_stock_market_tab, get_ticker_from_name, display_trading_value
from pykrx import stock
import time
import plotly.graph_objects as go
import numpy as np
import os
import FinanceDataReader as fdr
from streamlit_option_menu import option_menu
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹ ë¬¸ ê¸°ì‚¬ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'newspaper_articles' not in st.session_state:
    st.session_state['newspaper_articles'] = None
if 'paper_date' not in st.session_state:
    st.session_state['paper_date'] = None
if 'search_articles' not in st.session_state:
    st.session_state['search_articles'] = None
if 'current_search_keyword' not in st.session_state:
    st.session_state['current_search_keyword'] = None
if 'filtered_articles' not in st.session_state:
    st.session_state['filtered_articles'] = None
if 'ai_report' not in st.session_state:
    st.session_state['ai_report'] = None
if 'stock_data' not in st.session_state:
    st.session_state['stock_data'] = None
if 'stock_date' not in st.session_state:
    st.session_state['stock_date'] = None
if 'stock_filtered_data' not in st.session_state:
    st.session_state['stock_filtered_data'] = None

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .category-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #333;
        margin: 1rem 0 0.5rem 0;
        background-color: #f0f2f6;
        padding: 0.5rem;
        border-radius: 5px;
    }
    .article-item {
        background-color: #f8f9fa;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
        border-left: 4px solid #1f77b4;
    }
    .search-box {
        background-color: #e9ecef;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .newspaper-section {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .stButton > button {
        width: 100%;
    }
    .ai-report {
        background-color: #f8f9fa;
        padding: 2rem;
        margin: 1rem 0;
        border-radius: 10px;
        border: 1px solid #e9ecef;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .ai-report h3 {
        color: #1f77b4;
        margin-bottom: 1.5rem;
    }
    .ai-report p {
        line-height: 1.6;
        margin-bottom: 1rem;
    }
    .ai-report ul {
        margin-left: 1.5rem;
        margin-bottom: 1rem;
    }
    .ai-report li {
        margin-bottom: 0.5rem;
    }
    /* ì‚¬ì´ë“œë°” ë©”ë‰´ ìŠ¤íƒ€ì¼ë§ */
    .css-1d391kg {
        padding: 0.5rem 0;
    }
    .css-1d391kg .stRadio > div {
        padding: 0.5rem 1rem;
    }
    .css-1d391kg .stRadio > div:hover {
        background-color: #f0f2f6;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)

def check_secrets():
    """secrets ì„¤ì • í™•ì¸ - í™”ë©´ì— ë…¸ì¶œí•˜ì§€ ì•ŠìŒ"""
    missing_secrets = []
    api_available = False
    
    try:
        client_id = st.secrets["naver_api"]["client_id"]
        client_secret = st.secrets["naver_api"]["client_secret"]
        if client_id and client_secret:
            api_available = True
    except KeyError:
        missing_secrets.append("ë„¤ì´ë²„ API í‚¤")
    
    return api_available, missing_secrets

def remove_duplicates(articles):
    """ì¤‘ë³µ ê¸°ì‚¬ ì œê±°"""
    seen_urls = set()
    unique_articles = []
    
    for article in articles:
        if article['url'] not in seen_urls:
            seen_urls.add(article['url'])
            unique_articles.append(article)
    
    return unique_articles

def create_excel_download(articles):
    """ì—‘ì…€ íŒŒì¼ ìƒì„±"""
    if articles is None:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            pd.DataFrame().to_excel(writer, index=False)
        return output.getvalue()
        
    df = pd.DataFrame(articles)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='ì‹ ë¬¸ê¸°ì‚¬')
    return output.getvalue()

def create_text_download(articles, date):
    """í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
    if articles is None:
        return "ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    text_content = f"ğŸ“° {date.strftime('%Yë…„ %mì›” %dì¼')}ì˜ ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ\n\n"
    
    newspaper_groups = {}
    for article in articles:
        newspaper = article['newspaper']
        if newspaper not in newspaper_groups:
            newspaper_groups[newspaper] = []
        newspaper_groups[newspaper].append(article)
    
    for newspaper, articles_list in newspaper_groups.items():
        text_content += f"ğŸ“Œ [{newspaper}]\n"
        for article in articles_list:
            page_info = f"[{article['page']}] " if article['page'] else ""
            text_content += f"ğŸ”¹ {page_info}{article['title']}\n   {article['url']}\n"
        text_content += "\n"
    
    return text_content

def create_search_excel_download(articles):
    """ê²€ìƒ‰ ê²°ê³¼ ì—‘ì…€ íŒŒì¼ ìƒì„±"""
    df = pd.DataFrame(articles)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='ê²€ìƒ‰ê²°ê³¼')
    return output.getvalue()

def create_search_csv_download(articles):
    """ê²€ìƒ‰ ê²°ê³¼ CSV íŒŒì¼ ìƒì„±"""
    df = pd.DataFrame(articles)
    return df.to_csv(index=False).encode('utf-8-sig')

def create_search_text_download(articles, keyword):
    """ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
    text_content = f"ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼\n"
    text_content += f"ê²€ìƒ‰ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}\n"
    text_content += f"ì´ {len(articles)}ê°œ ê¸°ì‚¬\n\n"
    
    for i, article in enumerate(articles, 1):
        text_content += f"{i}. {article['title']}\n"
        text_content += f"   ìš”ì•½: {article['description']}\n"
        text_content += f"   ë°œí–‰ì¼: {article['pubDate']}\n"
        text_content += f"   ì¶œì²˜: {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n"
        text_content += f"   ë§í¬: {article['link']}\n\n"
    
    return text_content

def generate_ai_report(articles: List[Dict], date: datetime) -> str:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    try:
        # Google API í‚¤ í™•ì¸
        if 'google_api' not in st.secrets or 'api_key' not in st.secrets['google_api']:
            raise ValueError("Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Gemini API ì„¤ì •
        genai.configure(api_key=st.secrets['google_api']['api_key'])
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # ê¸°ì‚¬ ë°ì´í„° ì¤€ë¹„
        articles_text = []
        for article in articles:
            articles_text.append(f"ì œëª©: {article['title']}\nì‹ ë¬¸ì‚¬: {article['newspaper']}\në§í¬: {article['url']}\n")
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ### ğŸ¯ ì‘ì—… ëª©í‘œ
        ì¡°ê°„ì‹ ë¬¸ì— ê²Œì¬ëœ ê¸°ì‚¬ë“¤ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ë…ìë“¤ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.

        ### ğŸ“‹ ì…ë ¥ ë°ì´í„°
        - ì¡°ê°„ ì‹ ë¬¸ì— ê²Œì¬ëœ ê¸°ì‚¬ ëª©ë¡
        - ê° ê¸°ì‚¬ì˜ ì œëª©, ì‹ ë¬¸ì‚¬, ë§í¬ ì •ë³´ í¬í•¨

        ### ğŸ—ï¸ ì¶œë ¥ êµ¬ì¡°

        #### 1. ì „ì²´ ê¸€ ì œëª© ì‘ì„±
        - í˜•ì‹: "ğŸ“° [ë‚ ì§œ] ì¡°ê°„ì‹ ë¬¸ ì¢…í•© - [ì£¼ìš” ì´ìŠˆ 2-3ê°œ í‚¤ì›Œë“œ]"
        - ì˜ˆì‹œ: "ğŸ“° 2025ë…„ 5ì›” 28ì¼ ì¡°ê°„ì‹ ë¬¸ ì¢…í•© - ëŒ€ì„  ë§‰íŒ ë„¤ê±°í‹°ë¸Œ ê³µì„¸ì™€ ê²½ì œ íšŒë³µ ì‹ í˜¸"

        #### 2. ì „ì²´ ìš”ì•½ë¬¸ ì‘ì„± (150-200ì)
        - ë‹¹ì¼ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 3-4ê°œë¥¼ í¬í•¨
        - ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, êµ­ì œ ë¶„ì•¼ì˜ ê· í˜• ìˆëŠ” ìš”ì•½
        - ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬

        #### 3. ì„¹ì…˜ë³„ ê¸°ì‚¬ ë¶„ë¥˜ ë° ì‘ì„±

        **ğŸ”¥ ì˜¤ëŠ˜ì˜ Top ì´ìŠˆ (5ê°œ í—¤ë“œë¼ì¸)**
        - ì„ ì • ê¸°ì¤€: 
          * ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ì—ì„œ ê³µí†µìœ¼ë¡œ ë‹¤ë£¬ ê¸°ì‚¬
          * ì‚¬íšŒì  íŒŒê¸‰ë ¥ì´ í° ì‚¬ê±´
          * êµ­ë¯¼ ìƒí™œì— ì§ì ‘ì  ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì´ìŠˆ
        - ê° ê¸°ì‚¬ì˜ ì œëª©ë§Œ ì‘ì„±

        **ğŸ›ï¸ ì •ì¹˜/ì‚¬íšŒ (5ê°œ ê¸°ì‚¬)**
        - ëŒ€ì„ , ì •ì¹˜ì¸ ë™í–¥, ì •ì±… ë°œí‘œ, ì‚¬íšŒ ì´ìŠˆ í¬í•¨
        - ë‚´ë€ ìˆ˜ì‚¬, ì„ ê±° ê´€ë ¨, ì‚¬íšŒ ì œë„ ë³€í™” ë“±

        **ğŸ’° ê²½ì œ/ì‚°ì—… (5ê°œ ê¸°ì‚¬)**
        - ê¸°ì—… ì‹¤ì , ê²½ì œ ì§€í‘œ, ì‚°ì—… ë™í–¥, ê¸ˆìœµ ì •ì±…
        - ìˆ˜ì¶œì…, ì£¼ì‹ì‹œì¥, ë¶€ë™ì‚°, ì†Œë¹„ íŠ¸ë Œë“œ ë“±

        **ğŸ¤– ê¸°ìˆ /AI (5ê°œ ê¸°ì‚¬)**
        - IT, ì¸ê³µì§€ëŠ¥, ì‚¬ì´ë²„ë³´ì•ˆ, í†µì‹ , í˜ì‹  ê¸°ìˆ 
        - ê¸°ì—…ì˜ ê¸°ìˆ  ê°œë°œ, ë””ì§€í„¸ ì „í™˜ ê´€ë ¨
        
        **ğŸŒ êµ­ì œ/ê¸€ë¡œë²Œ (5ê°œ ê¸°ì‚¬)**
        - í•´ì™¸ ì •ì¹˜, êµ­ì œ ê²½ì œ, ì™¸êµ ê´€ê³„
        - ë¯¸êµ­, ì¤‘êµ­, ì¼ë³¸ ë“± ì£¼ìš”êµ­ ë™í–¥

        **ğŸ¤ ì—°ì˜ˆ/ë¬¸í™” (5ê°œ ê¸°ì‚¬)**
        - ì—°ì˜ˆê³„ ì†Œì‹, ë¬¸í™” í–‰ì‚¬, í•œë¥˜, ì˜ˆìˆ  ê´€ë ¨
        - K-ì»¬ì²˜, ì—”í„°í…Œì¸ë¨¼íŠ¸ ì‚°ì—… ë™í–¥

        **ğŸŒï¸ ìŠ¤í¬ì¸  (5ê°œ ê¸°ì‚¬)**
        - í”„ë¡œìŠ¤í¬ì¸ , êµ­ì œëŒ€íšŒ, ì„ ìˆ˜ ë™í–¥
        - ì•¼êµ¬, ì¶•êµ¬, ê³¨í”„ ë“± ì£¼ìš” ìŠ¤í¬ì¸  ì´ìŠˆ
        
        ### ğŸ“ ê° ê¸°ì‚¬ ì‘ì„± í˜•ì‹
        ### [ìˆœë²ˆ]. [ê¸°ì‚¬ ì œëª©]
        **ìš”ì•½**: [í•µì‹¬ ë‚´ìš©ì„ 50ì ì´ë‚´ë¡œ ìš”ì•½]
        **ë§í¬**: [ì›ë¬¸ ë§í¬]
        ### ê°€ë…ì„± ìˆê²Œ ì¤„ë°”ê¿ˆì„ ì´ìš©í•  ê²ƒ.     
        ### ì—¬ëŸ¬ ê¸°ì‚¬ë§í¬ë¥´ í†µí•©í•  ê²½ìš° ì²«ë²ˆì§¸ ê¸°ì‚¬ ë§í¬ë¥¼ ë„£ì–´ì¤„ ê²ƒ.  

        ### ğŸ·ï¸ í•´ì‹œíƒœê·¸ ì‘ì„± (30ê°œ)
        - ì£¼ìš” ì¸ë¬¼ëª…, ê¸°ê´€ëª…, ì´ìŠˆ í‚¤ì›Œë“œ í¬í•¨
        - íŠ¸ë Œë”© ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ìš°ì„  ì„ íƒ
        - ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ë¬¸í™” ë¶„ì•¼ ê· í˜• ìˆê²Œ ë°°ì¹˜
        - í•œê¸€ í•´ì‹œíƒœê·¸ë¡œ ì‘ì„± (#ëŒ€ì„ 2025, #ê²½ì œíšŒë³µ ë“±)

        ### ğŸ¨ ì‘ì„± ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
        - **ê°ê´€ì  í†¤**: íŠ¹ì • ì •ì¹˜ì  ì„±í–¥ ë°°ì œ
        - **ë…ì ì¹œí™”ì **: ì „ë¬¸ ìš©ì–´ ìµœì†Œí™”, ì‰¬ìš´ ì„¤ëª…
        - **ê°„ê²°ì„±**: í•µì‹¬ë§Œ ì¶”ë ¤ì„œ ì „ë‹¬
        - **ê· í˜•ì„±**: ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì´ìŠˆë¥¼ ê³ ë¥´ê²Œ ë‹¤ë£¸
        - **ì‹œì˜ì„±**: ë‹¹ì¼ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ ìš°ì„  ë°°ì¹˜

        ### ğŸ” ê¸°ì‚¬ ì„ ë³„ ê¸°ì¤€
        1. **ì¤‘ìš”ë„**: ì‚¬íšŒì  íŒŒê¸‰ë ¥ê³¼ ê´€ì‹¬ë„
        2. **ì‹ ë¢°ì„±**: ì£¼ìš” ì–¸ë¡ ì‚¬ ë³´ë„ ì—¬ë¶€
        3. **ë‹¤ì–‘ì„±**: ë¶„ì•¼ë³„ ê· í˜• ìˆëŠ” ì„ íƒ
        4. **ë…ì°½ì„±**: ìƒˆë¡œìš´ ì •ë³´ë‚˜ ê´€ì  ì œê³µ
        5. **ì—°ê´€ì„±**: ë…ìì˜ ì¼ìƒìƒí™œê³¼ì˜ ê´€ë ¨ì„±

        ### âš ï¸ ì£¼ì˜ì‚¬í•­
        - ì‚¬ì‹¤ í™•ì¸ì´ ì–´ë ¤ìš´ ì¶”ì¸¡ì„± ë‚´ìš© ë°°ì œ
        - ê· í˜• ì¡íŒ ì‹œê°ìœ¼ë¡œ ì´ìŠˆ ì „ë‹¬
        - ë§í¬ëŠ” ë°˜ë“œì‹œ ì •í™•í•œ URL ì‚¬ìš©

        ê¸°ì‚¬ ëª©ë¡:
        {json.dumps(articles_text, ensure_ascii=False, indent=2)}
        """
        
        # AI ìš”ì•½ ìƒì„±
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        return f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def create_ai_report_download(articles, date):
    """AI ë³´ê³ ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
    if articles is None:
        return "ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        
    report_content = f"ğŸ“Š {date.strftime('%Yë…„ %mì›” %dì¼')} ì‹ ë¬¸ ê¸°ì‚¬ AI ìš”ì•½ ë³´ê³ ì„œ\n\n"
    report_content += generate_ai_report(articles, date)
    return report_content

def newspaper_collection_tab():
    st.markdown("### ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘")
    st.markdown("ì¢…ì´ ì‹ ë¬¸ì— ì‹¤ì œë¡œ ì‹¤ë¦° ê¸°ì‚¬ë§Œ ìˆ˜ì§‘í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")
    
    # ë‚ ì§œ ì„ íƒì„ ë§¨ ìœ„ë¡œ ì´ë™
    KST = timezone(timedelta(hours=9))
    current_date = datetime.now(KST).date()
    
    selected_date = st.date_input(
        "ğŸ“… ìˆ˜ì§‘í•  ë‚ ì§œ ì„ íƒ",
        value=current_date,
        max_value=current_date,
        help="ìˆ˜ì§‘í•˜ê³  ì‹¶ì€ ì‹ ë¬¸ ë°œí–‰ì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        key="date_picker"
    )
    
    st.markdown("---")
    
    # ì‹ ë¬¸ì‚¬ ì„ íƒ ì„¹ì…˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown('<div class="category-header">ğŸ“Š ê²½ì œ ì‹ ë¬¸</div>', unsafe_allow_html=True)
        with st.container():
            economic_papers = {
                "ë§¤ì¼ê²½ì œ": "009",
                "ë¨¸ë‹ˆíˆ¬ë°ì´": "008", 
                "ì„œìš¸ê²½ì œ": "011",
                "ì´ë°ì¼ë¦¬": "018",
                "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": "014",
                "í•œêµ­ê²½ì œ": "015"
            }
            
            economic_all = st.checkbox("ì „ì²´ ì„ íƒ", key="economic_all")
            economic_selected = []
            
            for paper, oid in economic_papers.items():
                checked = st.checkbox(paper, value=economic_all, key=f"economic_{oid}")
                if checked:
                    economic_selected.append((paper, oid))
    
    with col2:
        st.markdown('<div class="category-header">ğŸ“‹ ì¢…í•©ì¼ê°„ì§€(ì¡°ê°„)</div>', unsafe_allow_html=True)
        with st.container():
            general_papers = {
                "ê²½í–¥ì‹ ë¬¸": "032",
                "êµ­ë¯¼ì¼ë³´": "005",
                "ë™ì•„ì¼ë³´": "020",
                "ì„œìš¸ì‹ ë¬¸": "081",
                "ì„¸ê³„ì¼ë³´": "022",
                "ì¡°ì„ ì¼ë³´": "023",
                "ì¤‘ì•™ì¼ë³´": "025",
                "í•œê²¨ë ˆ": "028",
                "í•œêµ­ì¼ë³´": "469",
                "ë””ì§€í„¸íƒ€ì„ìŠ¤": "029",
                "ì „ìì‹ ë¬¸": "030"
            }
            
            general_all = st.checkbox("ì „ì²´ ì„ íƒ", key="general_all")
            general_selected = []
            
            for paper, oid in general_papers.items():
                checked = st.checkbox(paper, value=general_all, key=f"general_{oid}")
                if checked:
                    general_selected.append((paper, oid))
    
    with col3:
        st.markdown('<div class="category-header">ğŸŒ† ì„ê°„ ì‹ ë¬¸</div>', unsafe_allow_html=True)
        with st.container():
            evening_papers = {
                "ë¬¸í™”ì¼ë³´": "021",
                "í—¤ëŸ´ë“œê²½ì œ": "016", 
                "ì•„ì‹œì•„ê²½ì œ": "277"
            }
            
            evening_all = st.checkbox("ì „ì²´ ì„ íƒ", key="evening_all")
            evening_selected = []
            
            for paper, oid in evening_papers.items():
                checked = st.checkbox(paper, value=evening_all, key=f"evening_{oid}")
                if checked:
                    evening_selected.append((paper, oid))
    
    st.markdown("---")
    
    # í¬ë¡¤ë§ ì‹œì‘ ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", type="primary", use_container_width=True, key="btn_start_crawling"):
            all_selected = economic_selected + general_selected + evening_selected
            
            if not all_selected:
                st.error("âŒ ìµœì†Œ í•˜ë‚˜ì˜ ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            collector = NewsCollector()
            
            try:
                status_text.text(f"ğŸš€ {len(all_selected)}ê°œ ì‹ ë¬¸ì‚¬ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘...")
                progress_bar.progress(20)
                
                # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥´ê²Œ ìˆ˜ì§‘ (í…Œì´ë¸” í˜•íƒœë¡œ ìƒíƒœ í‘œì‹œ)
                all_articles = collector.crawl_multiple_papers(all_selected, selected_date.strftime("%Y%m%d"))
                
                progress_bar.progress(80)
                
                # ì¤‘ë³µ ì œê±°
                unique_articles = remove_duplicates(all_articles)
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['newspaper_articles'] = unique_articles
                st.session_state['paper_date'] = selected_date
                
                status_text.text(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(unique_articles)}ê°œ ê¸°ì‚¬")
                progress_bar.progress(100)
                
                if len(unique_articles) == 0:
                    st.warning("âš ï¸ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‚ ì§œë‚˜ ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•´ë³´ì„¸ìš”.")
                else:
                    st.success(f"ğŸ‰ {len(all_selected)}ê°œ ì‹ ë¬¸ì‚¬ì—ì„œ ì´ {len(unique_articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                st.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            finally:
                collector.close()
    
    # ê²°ê³¼ í‘œì‹œ
    if 'newspaper_articles' in st.session_state:
        display_newspaper_results()

def display_newspaper_results():
    articles = st.session_state['newspaper_articles']
    paper_date = st.session_state['paper_date']
    
    st.markdown("---")
    
    # articlesê°€ Noneì´ë©´ í•¨ìˆ˜ ì¢…ë£Œ
    if articles is None:
        st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•˜ê³  í¬ë¡¤ë§ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return
    
    # ê²°ê³¼ í‘œì‹œ (ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì•„ë˜ë¡œ ì´ë™)
    if paper_date is not None:
        st.markdown(f"### ğŸ“° {paper_date.strftime('%Yë…„ %mì›” %dì¼')}ì˜ ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ")
    else:
        st.markdown("### ğŸ“° ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ")
    
    st.markdown(f"**ì´ {len(articles)}ê°œ ê¸°ì‚¬**")
    
    if len(articles) == 0:
        st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²€ìƒ‰ ê¸°ëŠ¥ (ë²„íŠ¼ ì •ë ¬ ìˆ˜ì •)
    col1, col2, col3 = st.columns([3, 1, 1])

    with col1:
        search_term = st.text_input("ğŸ” ê¸°ì‚¬ ê²€ìƒ‰", placeholder="ì œëª©ìœ¼ë¡œ ê²€ìƒ‰...", key="input_search_articles_newspaper")

    with col2:
        # ë¼ë²¨ì„ ì¶”ê°€í•˜ì—¬ ë†’ì´ ë§ì¶¤
        st.markdown("&nbsp;", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„
        if st.button("ê²€ìƒ‰", key="btn_search_articles_newspaper", use_container_width=True):
            if search_term:
                filtered_articles = [
                    article for article in articles 
                    if search_term.lower() in article['title'].lower()
                ]
                st.session_state['filtered_articles'] = filtered_articles
            else:
                st.session_state['filtered_articles'] = articles

    with col3:
        # ë¼ë²¨ì„ ì¶”ê°€í•˜ì—¬ ë†’ì´ ë§ì¶¤
        st.markdown("&nbsp;", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„
        if st.button("ì´ˆê¸°í™”", key="btn_reset_articles_newspaper", use_container_width=True):
            st.session_state['filtered_articles'] = articles
            st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # í‘œì‹œí•  ê¸°ì‚¬ ê²°ì •
    display_articles = st.session_state.get('filtered_articles', articles)
    
    # display_articlesê°€ Noneì´ë©´ articles ì‚¬ìš©
    if display_articles is None:
        display_articles = articles
    
    # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ê²€ìƒ‰ ê¸°ëŠ¥ ì•„ë˜ë¡œ ì´ë™
    st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        excel_data = create_excel_download(display_articles)
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"newspaper_articles_{paper_date.strftime('%Y%m%d') if paper_date else datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="btn_download_newspaper_excel"
        )
    
    with col2:
        text_data = create_text_download(display_articles, paper_date if paper_date else datetime.now())
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=text_data,
            file_name=f"newspaper_articles_{paper_date.strftime('%Y%m%d') if paper_date else datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_newspaper_text"
        )
    
    with col3:
        if st.button("ğŸ“‹ í´ë¦½ë³´ë“œ ë³µì‚¬", key="btn_copy_newspaper_text"):
            copy_text = create_text_download(display_articles, paper_date if paper_date else datetime.now())
            st.code(copy_text, language="text")
            st.success("âœ… í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë³µì‚¬í•˜ì„¸ìš”.")
    
    with col4:
        if st.button("ğŸ¤– AI ë³´ê³ ì„œ ìƒì„±", key="btn_generate_ai_report"):
            with st.spinner("AIê°€ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ê³  ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                report_text = create_ai_report_download(display_articles, paper_date if paper_date else datetime.now())
                st.session_state['ai_report'] = report_text
                st.success("âœ… AI ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
    
    st.markdown("---")
    
    # AI ë³´ê³ ì„œê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if 'ai_report' in st.session_state and st.session_state['ai_report'] is not None:
        st.markdown("### ğŸ“Š AI ìš”ì•½ ë³´ê³ ì„œ")
        st.markdown(st.session_state['ai_report'])
        st.download_button(
            label="ğŸ“‘ AI ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=st.session_state['ai_report'],
            file_name=f"ai_report_{paper_date.strftime('%Y%m%d') if paper_date else datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_ai_report"
        )
        st.markdown("---")
    
    # ì‹ ë¬¸ì‚¬ë³„ë¡œ ê·¸ë£¹í™”
    newspaper_groups = {}
    for article in display_articles:
        newspaper = article['newspaper']
        if newspaper not in newspaper_groups:
            newspaper_groups[newspaper] = []
        newspaper_groups[newspaper].append(article)
    
    # ì‹ ë¬¸ì‚¬ë³„ ê¸°ì‚¬ í‘œì‹œ
    for newspaper, articles_list in newspaper_groups.items():
        st.markdown(f"#### ğŸ“Œ [{newspaper}] ({len(articles_list)}ê°œ)")
        for article in articles_list:
            page_info = f"[{article['page']}] " if article['page'] else ""
            st.markdown(f"ğŸ”¹ {page_info}[{article['title']}]({article['url']})")

def naver_search_tab():
    st.markdown("### ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰")
    st.markdown("ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì´ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        keyword = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="input_search_keyword")
    
    with col2:
        # selectboxë¥¼ number_inputìœ¼ë¡œ ë³€ê²½
        max_articles = st.number_input(
            "ìµœëŒ€ ê¸°ì‚¬ ìˆ˜", 
            min_value=1, 
            max_value=1000, 
            value=100, 
            step=1, 
            key="input_max_articles",
            help="1ë¶€í„° 1000ê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        )
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True, key="btn_start_search"):
            if not keyword:
                st.error("âŒ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            searcher = NaverNewsSearcher()
            
            try:
                status_text.text("ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
                progress_bar.progress(50)
                
                articles = searcher.search_news(keyword, max_articles)
                
                progress_bar.progress(100)
                status_text.text(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! ì´ {len(articles)}ê°œ ê¸°ì‚¬")
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['search_articles'] = articles
                st.session_state['current_search_keyword'] = keyword
                
                if len(articles) == 0:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                else:
                    st.success(f"ğŸ‰ '{keyword}'ì— ëŒ€í•œ {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                progress_bar.progress(0)
                status_text.text("")
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if 'search_articles' in st.session_state:
        display_search_results()

def display_search_results():
    articles = st.session_state['search_articles']
    keyword = st.session_state['current_search_keyword']
    
    st.markdown("---")
    
    # articlesê°€ Noneì´ë©´ í•¨ìˆ˜ ì¢…ë£Œ
    if articles is None:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return
        
    st.markdown(f"### ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(articles)}ê°œ)")
    
    if len(articles) == 0:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ìƒë‹¨ìœ¼ë¡œ ì´ë™
    st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        excel_data = create_search_excel_download(articles)
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="btn_download_naver_search_excel"
        )
    
    with col2:
        csv_data = create_search_csv_download(articles)
        st.download_button(
            label="ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            key="btn_download_naver_search_csv"
        )
    
    with col3:
        text_data = create_search_text_download(articles, keyword)
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=text_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_naver_search_text"
        )
    
    st.markdown("---")
    
    # ê²°ê³¼ í‘œì‹œ ì˜µì…˜
    display_mode = st.radio("í‘œì‹œ ë°©ì‹", ["ìš”ì•½ ë³´ê¸°", "ì „ì²´ ë³´ê¸°"], horizontal=True, key="radio_display_mode")
    
    if display_mode == "ìš”ì•½ ë³´ê¸°":
        # ê°„ë‹¨í•œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
        for i, article in enumerate(articles, 1):
            st.markdown(f"**{i}.** [{article['title']}]({article['link']})")
            st.caption(f"ğŸ“… {article['pubDate']} | ğŸ“° {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            if article.get('description'):
                st.write(f"ğŸ’¬ {article['description'][:100]}...")
            st.markdown("---")
    else:
        # ìƒì„¸í•œ expander í˜•íƒœë¡œ í‘œì‹œ
        for i, article in enumerate(articles, 1):
            with st.expander(f"{i}. {article['title']}", expanded=False):
                st.markdown(f"**ìš”ì•½:** {article['description']}")
                st.markdown(f"**ë°œí–‰ì¼:** {article['pubDate']}")
                st.markdown(f"**ì¶œì²˜:** {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                st.markdown(f"**ë§í¬:** [ê¸°ì‚¬ ë³´ê¸°]({article['link']})")

def get_industry_info():
    """ì—…ì¢… ë° ì£¼ìš”ì œí’ˆ ì •ë³´ ìˆ˜ì§‘"""
    try:
        # KRX KIND ì‹œìŠ¤í…œ ìƒì¥ë²•ì¸ëª©ë¡ URL
        url = "https://kind.krx.co.kr/corpgeneral/corpList.do"
        params = {
            "method": "download",
            "searchType": "13"
        }
        
        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(url, params=params)
        response.raise_for_status()
        
        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # í…Œì´ë¸” ì°¾ê¸°
        table = soup.find('table')
        if not table:
            raise ValueError("ìƒì¥ë²•ì¸ëª©ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ì¶”ì¶œ
        data = []
        rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
        
        for row in rows:
            cols = row.find_all('td')
            if len(cols) >= 3:  # ìµœì†Œ 3ê°œ ì»¬ëŸ¼ í™•ì¸
                stock_code = cols[1].text.strip()  # ì¢…ëª©ì½”ë“œ
                industry = cols[2].text.strip()    # ì—…ì¢…
                main_product = cols[3].text.strip() if len(cols) > 3 else ''  # ì£¼ìš”ì œí’ˆ
                
                data.append({
                    'ì¢…ëª©ì½”ë“œ': stock_code,
                    'ì—…ì¢…': industry,
                    'ì£¼ìš”ì œí’ˆ': main_product
                })
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(data)
        
        # ì¢…ëª©ì½”ë“œ í¬ë§·íŒ…
        df['ì¢…ëª©ì½”ë“œ'] = df['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
        
        return df
        
    except Exception as e:
        st.error(f"ì—…ì¢… ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()

def collect_market_data(market: str, date: str) -> pd.DataFrame:
    """ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        # 1. ê°€ê²© ë³€ë™ ë°ì´í„° ìˆ˜ì§‘ (ì´ ë°ì´í„°ì— ëª¨ë“  í•„ìš”í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŒ)
        df = stock.get_market_price_change(date, date, market=market)
        time.sleep(0.3)  # API í˜¸ì¶œ ê°„ ë”œë ˆì´
        
        # 2. OHLCV ë°ì´í„° ìˆ˜ì§‘ (ê³ ê°€, ì €ê°€, ì‹œê°€ì´ì•¡ ì •ë³´)
        df_ohlcv = stock.get_market_ohlcv(date, market=market)
        time.sleep(0.3)  # API í˜¸ì¶œ ê°„ ë”œë ˆì´
        
        # 3. ê¸°ë³¸ ì§€í‘œ ë°ì´í„° ìˆ˜ì§‘
        df_fundamental = stock.get_market_fundamental(date, market=market)
        time.sleep(0.3)  # API í˜¸ì¶œ ê°„ ë”œë ˆì´
        
        # 4. ì—…ì¢… ì •ë³´ ìˆ˜ì§‘
        df_industry = get_industry_info()
        
        # 5. OHLCV ë°ì´í„° ë³‘í•© (ê³ ê°€, ì €ê°€, ì‹œê°€ì´ì•¡)
        if not df_ohlcv.empty:
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë³‘í•©
            df = df.merge(df_ohlcv[['ê³ ê°€', 'ì €ê°€', 'ì‹œê°€ì´ì•¡']], 
                         left_index=True, 
                         right_index=True, 
                         how='left')
        
        # 6. ê¸°ë³¸ ì§€í‘œ ë°ì´í„° ë³‘í•©
        if not df_fundamental.empty:
            df = df.merge(df_fundamental, 
                         left_index=True, 
                         right_index=True, 
                         how='left')
        
        # 7. ì—…ì¢… ì •ë³´ ë³‘í•©
        if not df_industry.empty:
            df = df.merge(df_industry, 
                         left_index=True, 
                         right_on='ì¢…ëª©ì½”ë“œ', 
                         how='left')
            df = df.drop('ì¢…ëª©ì½”ë“œ', axis=1)
        else:
            df['ì—…ì¢…'] = ''
            df['ì£¼ìš”ì œí’ˆ'] = ''
        
        # 8. ì‹œì¥êµ¬ë¶„ ì¶”ê°€
        df['ì‹œì¥êµ¬ë¶„'] = market
        
        return df
        
    except Exception as e:
        st.error(f"{market} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

def display_market_analysis(df: pd.DataFrame, date: datetime):
    """ì‹œì¥ ë°ì´í„° ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    # í˜„ì¬ ì‹œê°„ í‘œì‹œ
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.success(f"âœ… {len(df)}ê°œ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤! (ìµœì¢… ì—…ë°ì´íŠ¸: {current_time})")
    
    # ìš”ì•½ ì •ë³´
    st.markdown("### ğŸ“Š ì‹œì¥ ìš”ì•½")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ì¢…ëª© ìˆ˜", f"{len(df):,}ê°œ")
    with col2:
        avg_trading_value = df['ê±°ë˜ëŒ€ê¸ˆ'].mean()
        st.metric("í‰ê·  ê±°ë˜ëŒ€ê¸ˆ", f"{avg_trading_value/100000000:.0f}ì–µì›")
    with col3:
        st.metric("í‰ê·  ì‹œê°€ì´ì•¡", f"{df['ì‹œê°€ì´ì•¡'].mean()/100000000:.0f}ì–µì›")
    with col4:
        st.metric("í‰ê·  ë“±ë½ë¥ ", f"{df['ë“±ë½ë¥ '].mean():.2f}%")
    
    # ë“±ë½ë¥  ë¶„í¬ ì°¨íŠ¸
    st.markdown("### ğŸ“ˆ ë“±ë½ë¥  ë¶„í¬")
    fig = go.Figure(data=[go.Histogram(x=df['ë“±ë½ë¥ '], nbinsx=50)])
    fig.update_layout(
        title="ë“±ë½ë¥  ë¶„í¬ë„",
        xaxis_title="ë“±ë½ë¥  (%)",
        yaxis_title="ì¢…ëª© ìˆ˜"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ì‹œì¥ë³„ ì¢…ëª© ìˆ˜
    market_counts = df['ì‹œì¥êµ¬ë¶„'].value_counts()
    fig = go.Figure(data=[go.Pie(
        labels=market_counts.index,
        values=market_counts.values,
        hole=.3
    )])
    fig.update_layout(title="ì‹œì¥ë³„ ì¢…ëª© ë¶„í¬")
    st.plotly_chart(fig, use_container_width=True)
    
    # ìƒì„¸ ë°ì´í„° í‘œì‹œ
    st.markdown("### ğŸ“‹ ì¢…ëª© ìƒì„¸ ì •ë³´")
    
    # ì •ë ¬ ì˜µì…˜
    sort_column = st.selectbox(
        "ì •ë ¬ ê¸°ì¤€",
        options=['ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ë“±ë½ë¥ ', 'ì‹œê°€ì´ì•¡', 'ë³€ë™í­', 'PER', 'PBR', 'EPS', 'BPS', 'DIV', 'DPS'],
        index=3
    )
    
    df = df.sort_values(by=sort_column, ascending=False)
    
    # ë°ì´í„° í¬ë§·íŒ…
    display_df = df.copy()
    display_df['ì‹œê°€ì´ì•¡'] = display_df['ì‹œê°€ì´ì•¡'].apply(lambda x: f"{x/100000000:.0f}ì–µì›")
    display_df['ê±°ë˜ëŒ€ê¸ˆ'] = display_df['ê±°ë˜ëŒ€ê¸ˆ'].apply(lambda x: f"{x/100000000:.0f}ì–µì›")
    display_df['ê±°ë˜ëŸ‰'] = display_df['ê±°ë˜ëŸ‰'].apply(lambda x: f"{x:,}")
    display_df['ë³€ë™í­'] = display_df['ë³€ë™í­'].apply(lambda x: f"{x:,}")
    display_df['ë“±ë½ë¥ '] = display_df['ë“±ë½ë¥ '].apply(lambda x: f"{x:.2f}%")
    
    # ê¸°ë³¸ ì§€í‘œ í¬ë§·íŒ…
    for col in ['PER', 'PBR', 'EPS', 'BPS', 'DIV', 'DPS']:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(lambda x: f"{x:.2f}" if pd.notnull(x) else "-")
    
    # í‘œì‹œí•  ì—´ ì„ íƒ
    columns_to_display = [
        'ì¢…ëª©ëª…', 'ì‹œì¥êµ¬ë¶„', 'ì—…ì¢…', 'ì£¼ìš”ì œí’ˆ', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€', 
        'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ', 'ë“±ë½ë¥ ', 'ë³€ë™í­', 'ì‹œê°€ì´ì•¡',
        'PER', 'PBR', 'EPS', 'BPS', 'DIV', 'DPS'
    ]
    
    # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
    st.dataframe(
        display_df[columns_to_display],
        use_container_width=True,
        hide_index=True
    )
    
    # CSV ë‹¤ìš´ë¡œë“œ
    csv = df[columns_to_display].to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name=f"stock_data_{date.strftime('%Y%m%d')}.csv",
        mime="text/csv"
    )
    
    # ì§€í‘œ ì„¤ëª…
    st.markdown("### ğŸ“Š ì£¼ìš” ì§€í‘œ ì„¤ëª…")
    st.markdown("""
    - **PER (ì£¼ê°€ìˆ˜ìµë¹„ìœ¨)**: ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœì´ìµ(EPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ê¸°ì—…ì˜ ìˆ˜ìµì„±ê³¼ ì£¼ê°€ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‚®ì„ìˆ˜ë¡ ì €í‰ê°€ëœ ì£¼ì‹ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **PBR (ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨)**: ì£¼ê°€ë¥¼ ì£¼ë‹¹ìˆœìì‚°(BPS)ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ê¸°ì—…ì˜ ìˆœìì‚° ëŒ€ë¹„ ì£¼ê°€ì˜ ìˆ˜ì¤€ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 1 ë¯¸ë§Œì´ë©´ ìˆœìì‚°ë³´ë‹¤ ì €í‰ê°€ëœ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **EPS (ì£¼ë‹¹ìˆœì´ìµ)**: ê¸°ì—…ì˜ ìˆœì´ìµì„ ë°œí–‰ì£¼ì‹ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ì£¼ì£¼ê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ì´ìµì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    - **BPS (ì£¼ë‹¹ìˆœìì‚°)**: ê¸°ì—…ì˜ ìˆœìì‚°ì„ ë°œí–‰ì£¼ì‹ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, ì£¼ì£¼ê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ìˆœìì‚°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    - **DIV (ë°°ë‹¹ìˆ˜ìµë¥ )**: ì£¼ë‹¹ë°°ë‹¹ê¸ˆ(DPS)ì„ ì£¼ê°€ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ, íˆ¬ìê¸ˆì•¡ ëŒ€ë¹„ ë°°ë‹¹ìˆ˜ìµì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    - **DPS (ì£¼ë‹¹ë°°ë‹¹ê¸ˆ)**: ê¸°ì—…ì´ ì£¼ì£¼ì—ê²Œ ì§€ê¸‰í•˜ëŠ” ë°°ë‹¹ê¸ˆì„ ë°œí–‰ì£¼ì‹ìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤.
    """)

def display_stock_data():
    """ì „ì²´ ì¢…ëª© ì‹œì„¸ ì¡°íšŒ"""
    st.markdown("### ğŸ“Š ì „ì²´ ì¢…ëª© ì‹œì„¸ ì¡°íšŒ")
    
    # ë‚ ì§œ ì„ íƒ
    today = datetime.now()
    max_date = today.strftime("%Y%m%d")
    
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    
    # ë‚ ì§œ ì„ íƒ ìœ„ì ¯
    selected_date = st.date_input(
        "ì¡°íšŒ ë‚ ì§œ",
        value=today,
        max_value=today,
        help="ì¡°íšŒí•  ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # í•„í„°ë§ ì˜µì…˜
    col1, col2, col3 = st.columns([2, 5, 1])
    
    with col1:
        market_filter = st.multiselect(
            "ì‹œì¥ ì„ íƒ",
            options=['KOSPI', 'KOSDAQ'],
            default=['KOSPI', 'KOSDAQ']
        )
    
    with col2:
        st.markdown("ì£¼ê°€ ë²”ìœ„")
        price_col1, price_col2 = st.columns(2)
        with price_col1:
            min_price = st.number_input(
                "ìµœì†Œ ì£¼ê°€",
                min_value=0,
                max_value=1500000,
                value=0,
                step=1000,
                help="ìµœì†Œ ì£¼ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
        with price_col2:
            max_price = st.number_input(
                "ìµœëŒ€ ì£¼ê°€",
                min_value=0,
                max_value=1500000,
                value=1500000,
                step=1000,
                help="ìµœëŒ€ ì£¼ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            )
        
        # ìŠ¬ë¼ì´ë”ëŠ” ì…ë ¥ëœ ê°’ê³¼ ë™ê¸°í™”
        price_range = st.slider(
            "",
            min_value=0,
            max_value=1500000,
            value=(min_price, max_price),
            step=1000,
            help="ì›í•˜ëŠ” ì£¼ê°€ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col3:
        volume_filter = st.number_input(
            "ìµœì†Œ ê±°ë˜ëŸ‰",
            min_value=0,
            value=0,
            step=1000
        )
    
    # ë°ì´í„° ì¡°íšŒ ë²„íŠ¼
    if st.button("ğŸ” ë°ì´í„° ì¡°íšŒ", type="primary"):
        with st.spinner('ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            try:
                # KOSPI ë°ì´í„° ìˆ˜ì§‘
                kospi_df = collect_market_data("KOSPI", selected_date.strftime("%Y%m%d"))
                time.sleep(1)  # API í˜¸ì¶œ ê°„ ë”œë ˆì´
                
                # KOSDAQ ë°ì´í„° ìˆ˜ì§‘
                kosdaq_df = collect_market_data("KOSDAQ", selected_date.strftime("%Y%m%d"))
                
                # ë°ì´í„° í•©ì¹˜ê¸°
                df = pd.concat([kospi_df, kosdaq_df])
                
                # í•„í„°ë§
                filtered_df = df[
                    (df['ì‹œì¥êµ¬ë¶„'].isin(market_filter)) &
                    (df['ì¢…ê°€'].between(price_range[0], price_range[1])) &
                    (df['ê±°ë˜ëŸ‰'] >= volume_filter)
                ]
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['stock_data'] = df
                st.session_state['stock_filtered_data'] = filtered_df
                st.session_state['stock_date'] = selected_date
                
                if len(filtered_df) > 0:
                    display_market_analysis(filtered_df, selected_date)
                else:
                    st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    else:
        # ì €ì¥ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state['stock_filtered_data'] is not None:
            display_market_analysis(st.session_state['stock_filtered_data'], st.session_state['stock_date'])

def display_stock_market_tab():
    """ì˜¤ëŠ˜ì˜ ì¦ì‹œ íƒ­ í‘œì‹œ"""
    st.markdown("### ğŸ“ˆ ì˜¤ëŠ˜ì˜ ì¦ì‹œ(ì¢…ë£Œì¼ ê¸°ì¤€)")
    
    # ë‚ ì§œ ì„ íƒ
    today = datetime.now()
    max_date = today.strftime("%Y%m%d")
    
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    
    # ë‚ ì§œ ì„ íƒ ìœ„ì ¯
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input(
            "ì‹œì‘ì¼",
            value=today - timedelta(days=90),  # 90ì¼ ì „ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •
            max_value=today,
            help="ì¡°íšŒ ì‹œì‘ì¼ì„ ì„ íƒí•˜ì„¸ìš”"
        )
    with col2:
        end_date = st.date_input(
            "ì¢…ë£Œì¼",
            value=today,
            max_value=today,
            help="ì¡°íšŒ ì¢…ë£Œì¼ì„ ì„ íƒí•˜ì„¸ìš”"
        )
    
    # 1. ì£¼ìš” ì§€ìˆ˜ ì‹œì„¸
    st.markdown("#### ğŸ“Š ì£¼ìš” ì§€ìˆ˜")
    index_codes = {
        'KOSPI': 'KS11',
        'KOSDAQ': 'KQ11',
        'S&P 500': 'US500',
        'NASDAQ': 'IXIC',
        'ë‹¤ìš°ì¡´ìŠ¤': 'DJI',
        'ë‹ˆì¼€ì´225': 'N225',
        'í•­ì…ì§€ìˆ˜': 'HSI'
    }

    cols = st.columns(len(index_codes))
    for i, (name, code) in enumerate(index_codes.items()):
        try:
            df = fdr.DataReader(code, start_date, end_date)
            delta = df['Close'].pct_change().iloc[-1] * 100
            cols[i].metric(label=name, value=f"{df['Close'].iloc[-1]:,.2f}", delta=f"{delta:.2f}%")
        except Exception as e:
            cols[i].error(f"{name} ì§€ìˆ˜ ì˜¤ë¥˜: {e}")
    
    st.markdown("---")
    
    # 2. ê±°ë˜ì‹¤ì  ë°ì´í„° í‘œì‹œ
    display_trading_value(start_date, end_date)
    
    # 3. í™˜ìœ¨ & ì›ìì¬ ì‹œì„¸
    st.markdown("#### ğŸ’± í™˜ìœ¨ ë° ì›ìì¬ ê°€ê²©")
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("##### í™˜ìœ¨")
        fx_codes = {'ë¯¸êµ­ ë‹¬ëŸ¬ (USD/KRW)': 'USD/KRW', 'ì¼ë³¸ ì—”í™” (JPY/KRW)': 'JPY/KRW'}
        for label, code in fx_codes.items():
            try:
                fx = fdr.DataReader(code, start_date, end_date)
                if not fx.empty:
                    st.line_chart(fx['Close'].rename(label), height=150)
                else:
                    st.warning(f"{label} ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"{label} ë°ì´í„° ì˜¤ë¥˜: {e}")

    with col2:
        st.markdown("##### ì›ìì¬")
        cm_codes = {'ì„œë¶€í…ì‚¬ìŠ¤ì‚° ì›ìœ  (WTI)': 'WTI', 'ê¸ˆ (GOLD)': 'GOLD'}
        for label, code in cm_codes.items():
            try:
                cm = fdr.DataReader(code, start_date, end_date)
                if not cm.empty:
                    st.line_chart(cm['Close'].rename(label), height=150)
                else:
                    st.warning(f"{label} ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"{label} ë°ì´í„° ì˜¤ë¥˜: {e}")
    
    st.markdown("---")
    
    # 4. ê°œë³„ ì¢…ëª© ì¡°íšŒ
    st.markdown("#### ğŸ” ê°œë³„ ì¢…ëª©/ETF ì¡°íšŒ")
    code_input = st.text_input("ì¢…ëª©ì½”ë“œ, í‹°ì»¤ ë˜ëŠ” ì¢…ëª©ëª… ì…ë ¥ (ì˜ˆ: 005930, AAPL, ì‚¼ì„±ì „ì ë“±)", value="005930")
    if code_input:
        try:
            # ì…ë ¥ê°’ì´ í‹°ì»¤/ì½”ë“œê°€ ì•„ë‹Œ ê²½ìš° ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰
            if not any(c.isdigit() for c in code_input) and not code_input.isupper():
                ticker = get_ticker_from_name(code_input)
                if ticker:
                    st.info(f"'{code_input}'ì˜ í‹°ì»¤/ì½”ë“œ: {ticker}")
                    code_input = ticker
                else:
                    st.warning(f"'{code_input}'ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return

            df_stock = fdr.DataReader(code_input, start_date, end_date)
            if df_stock.empty:
                st.warning(f"{code_input}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=df_stock.index, y=df_stock['Close'], mode='lines', name='ì¢…ê°€'))
                fig.update_layout(title=f"{code_input} ì£¼ê°€ ì¶”ì´", xaxis_title="ë‚ ì§œ", yaxis_title="ê°€ê²©")
                st.plotly_chart(fig, use_container_width=True)

                with st.expander("ğŸ“Š ê¸°ìˆ ì  ì§€í‘œ ë³´ê¸°"):
                    df_stock['SMA20'] = df_stock['Close'].rolling(window=20).mean()
                    df_stock['SMA60'] = df_stock['Close'].rolling(window=60).mean()
                    df_stock['EMA20'] = df_stock['Close'].ewm(span=20).mean()
                    df_stock['EMA60'] = df_stock['Close'].ewm(span=60).mean()

                    delta = df_stock['Close'].diff()
                    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                    rs = gain / loss
                    df_stock['RSI'] = 100 - (100 / (1 + rs))

                    ema12 = df_stock['Close'].ewm(span=12).mean()
                    ema26 = df_stock['Close'].ewm(span=26).mean()
                    df_stock['MACD'] = ema12 - ema26
                    df_stock['Signal'] = df_stock['MACD'].ewm(span=9).mean()

                    fig2 = go.Figure()
                    fig2.add_trace(go.Scatter(x=df_stock.index, y=df_stock['Close'], name='ì¢…ê°€'))
                    fig2.add_trace(go.Scatter(x=df_stock.index, y=df_stock['SMA20'], name='SMA20'))
                    fig2.add_trace(go.Scatter(x=df_stock.index, y=df_stock['SMA60'], name='SMA60'))
                    fig2.add_trace(go.Scatter(x=df_stock.index, y=df_stock['EMA20'], name='EMA20'))
                    fig2.add_trace(go.Scatter(x=df_stock.index, y=df_stock['EMA60'], name='EMA60'))
                    fig2.update_layout(title=f"{code_input} ì´ë™í‰ê· ì„  ë¹„êµ", xaxis_title="ë‚ ì§œ", yaxis_title="ê°€ê²©")
                    st.plotly_chart(fig2, use_container_width=True)

                    fig3 = go.Figure()
                    fig3.add_trace(go.Scatter(x=df_stock.index, y=df_stock['MACD'], name='MACD'))
                    fig3.add_trace(go.Scatter(x=df_stock.index, y=df_stock['Signal'], name='Signal'))
                    fig3.update_layout(title=f"{code_input} MACD", xaxis_title="ë‚ ì§œ", yaxis_title="ê°’")
                    st.plotly_chart(fig3, use_container_width=True)

                    fig4 = go.Figure()
                    fig4.add_trace(go.Scatter(x=df_stock.index, y=df_stock['RSI'], name='RSI'))
                    fig4.add_hline(y=70, line=dict(dash='dash', color='red'))
                    fig4.add_hline(y=30, line=dict(dash='dash', color='green'))
                    fig4.update_layout(title=f"{code_input} RSI", xaxis_title="ë‚ ì§œ", yaxis_title="RSI ê°’")
                    st.plotly_chart(fig4, use_container_width=True)

        except Exception as e:
            st.error(f"{code_input} ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def extract_stock_names(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¢…ëª©ëª… ì¶”ì¶œ"""
    # ì¢…ëª©ëª… íŒ¨í„´ (í•œê¸€ 2-10ì)
    pattern = r'[ê°€-í£]{2,10}(?:ì£¼ì‹|ì¦ê¶Œ|ê¸°ì—…|íšŒì‚¬|ì£¼)'
    matches = re.findall(pattern, text)
    return [match.replace('ì£¼ì‹', '').replace('ì¦ê¶Œ', '').replace('ê¸°ì—…', '').replace('íšŒì‚¬', '').replace('ì£¼', '') for match in matches]


def search_stock_news(keywords, start_date, end_date, max_articles):
    """íŠ¹ì§•ì£¼ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰"""
    searcher = NaverNewsSearcher()
    return searcher.search_stock_news(keywords, start_date, max_articles)

def display_stock_news_tab():
    """íŠ¹ì§•ì£¼ í¬ì°© íƒ­ í‘œì‹œ"""
    st.markdown("### ğŸ“ˆ íŠ¹ì§•ì£¼ í¬ì°©")
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œ ì„ íƒ
    default_keywords = ["íŠ¹ì§•ì£¼", "ê¸‰ë“±ì£¼", "ìƒí•œê°€", "ê¸‰ë“±ì„¸", "ê¸‰ë½ì„¸", 
                       "ê°•ì„¸", "ì•½ì„¸", "ê±°ë˜ëŸ‰ ì¦ê°€", "ì‹ ê³ ê°€", "ì‹ ì €ê°€"]
    
    # ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ ì…ë ¥
    custom_keyword = st.text_input(
        "ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥",
        help="ì›í•˜ëŠ” ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì…ë ¥ í›„ Enterë¥¼ ëˆ„ë¥´ë©´ í‚¤ì›Œë“œê°€ ì¶”ê°€ë©ë‹ˆë‹¤."
    )
    
    # ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œê°€ ì…ë ¥ë˜ë©´ default_keywordsì— ì¶”ê°€
    if custom_keyword and custom_keyword not in default_keywords:
        default_keywords.append(custom_keyword)
    
    # í‚¤ì›Œë“œ ì„ íƒ (ê¸°ë³¸ í‚¤ì›Œë“œ + ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ)
    selected_keywords = st.multiselect(
        "ê²€ìƒ‰ í‚¤ì›Œë“œ ì„ íƒ",
        options=default_keywords,
        default=default_keywords[:3]
    )
    
    # ì¡°íšŒ ë‚ ì§œ ì„ íƒ
    today = datetime.now()
    # ì£¼ë§ì¸ ê²½ìš° ê¸ˆìš”ì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
    if today.weekday() >= 5:  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        days_to_subtract = today.weekday() - 4
        today = today - timedelta(days=days_to_subtract)
    
    selected_date = st.date_input(
        "ì¡°íšŒ ë‚ ì§œ",
        value=today,
        max_value=today,
        help="ì¡°íšŒí•  ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )
    
    # ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì…ë ¥
    max_articles = st.number_input(
        "ìµœëŒ€ ê¸°ì‚¬ ìˆ˜",
        min_value=10,
        max_value=1000,
        value=100,
        step=10
    )
    
    if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary"):
        with st.spinner("ë‰´ìŠ¤ ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
            # 1. ë‰´ìŠ¤ ê²€ìƒ‰
            articles = search_stock_news(selected_keywords, selected_date, None, max_articles)
            
            # í‚¤ì›Œë“œë³„ ê¸°ì‚¬ ìˆ˜ ê³„ì‚°
            keyword_article_counts = {}
            for keyword in selected_keywords:
                count = sum(1 for article in articles if keyword in article['title'] or keyword in article['description'])
                keyword_article_counts[keyword] = count
            
            # 2. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒí•œ ë‚ ì§œ ê¸°ì¤€)
            market_data = {}
            all_stock_names = set()  # ëª¨ë“  ì¢…ëª©ëª…ì„ ì €ì¥í•  set
            
            for market in ['KOSPI', 'KOSDAQ']:
                try:
                    df = collect_market_data(market, selected_date.strftime("%Y%m%d"))
                    market_data[market] = df
                    # ì‹œì¥ ë°ì´í„°ì—ì„œ ì¢…ëª©ëª… ì¶”ì¶œ
                    all_stock_names.update(df['ì¢…ëª©ëª…'].tolist())
                except Exception as e:
                    st.error(f"{market} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # 3. ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¢…ëª©ëª… ë§¤ì¹­
            stock_articles = {}  # ì¢…ëª©ë³„ ê¸°ì‚¬ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            stock_keywords = {}  # ì¢…ëª©ë³„ ë§¤ì¹­ëœ í‚¤ì›Œë“œë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            matched_stocks = set()  # ë§¤ì¹­ëœ ì¢…ëª©ì„ ì¶”ì í•˜ê¸° ìœ„í•œ set
            
            for article in articles:
                # ê¸°ì‚¬ ì œëª©ê³¼ ë‚´ìš©ì—ì„œ ì¢…ëª©ëª… ì°¾ê¸°
                text = article['title'] + " " + article['description']
                
                # ê¸°ì‚¬ì— í¬í•¨ëœ í‚¤ì›Œë“œ ì°¾ê¸°
                matched_keywords = [keyword for keyword in selected_keywords if keyword in text]
                
                # ì‹œì¥ ë°ì´í„°ì˜ ëª¨ë“  ì¢…ëª©ëª…ê³¼ ë§¤ì¹­
                for stock_name in all_stock_names:
                    if stock_name in text:
                        if stock_name not in stock_articles:
                            stock_articles[stock_name] = []
                            stock_keywords[stock_name] = set()
                        stock_articles[stock_name].append(article)
                        stock_keywords[stock_name].update(matched_keywords)
                        matched_stocks.add(stock_name)
            
            # 4. ê²°ê³¼ ìƒì„±
            results = []
            for stock_name, articles in stock_articles.items():
                # í•´ë‹¹ ì¢…ëª©ì˜ ì‹œì¥ ë°ì´í„° ì°¾ê¸°
                for market, df in market_data.items():
                    stock_data = df[df['ì¢…ëª©ëª…'] == stock_name]
                    if not stock_data.empty:
                        stock = stock_data.iloc[0]
                        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
                        result = {
                            'ì¢…ëª©ëª…': stock['ì¢…ëª©ëª…'],
                            'ì‹œì¥êµ¬ë¶„': market,
                            'ì—…ì¢…': stock['ì—…ì¢…'],
                            'ì£¼ìš”ì œí’ˆ': stock['ì£¼ìš”ì œí’ˆ'],  # ì£¼ìš”ì œí’ˆ ì»¬ëŸ¼ ì¶”ê°€
                            'í˜„ì¬ê°€': stock['ì¢…ê°€'],
                            'ë“±ë½ë¥ ': stock['ë“±ë½ë¥ '],
                            'ê±°ë˜ëŸ‰': stock['ê±°ë˜ëŸ‰'],
                            'ì‹œê°€ì´ì•¡': stock['ì‹œê°€ì´ì•¡'],
                            'ê´€ë ¨ê¸°ì‚¬ìˆ˜': len(articles),
                            'ë§¤ì¹­í‚¤ì›Œë“œ': ', '.join(sorted(stock_keywords[stock_name]))
                        }
                        
                        # ê¸°ì‚¬ ì •ë³´ ì¶”ê°€ (ìµœëŒ€ 3ê°œ)
                        for i, article in enumerate(articles[:3], 1):
                            result.update({
                                f'ê¸°ì‚¬ì œëª©{i}': article['title'],
                                f'ê¸°ì‚¬ìš”ì•½{i}': article['description'],
                                f'ê¸°ì‚¬ë§í¬{i}': article['link']
                            })
                        
                        results.append(result)
            
            # 5. ê²€ìƒ‰ ê²°ê³¼ í†µê³„ í‘œì‹œ
            st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ í†µê³„")
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### í‚¤ì›Œë“œë³„ ê¸°ì‚¬ ìˆ˜")
                for keyword, count in keyword_article_counts.items():
                    st.write(f"- {keyword}: {count}ê°œ")
            
            with col2:
                st.markdown("#### ë§¤ì¹­ëœ ì¢…ëª© ìˆ˜")
                st.write(f"- ì´ {len(matched_stocks)}ê°œ ì¢…ëª©ì´ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # ì¢…ëª©ë³„ ê¸°ì‚¬ ìˆ˜ ë¶„í¬
                article_counts = [len(articles) for articles in stock_articles.values()]
                if article_counts:
                    st.write(f"- í‰ê·  {sum(article_counts)/len(article_counts):.1f}ê°œì˜ ê¸°ì‚¬ê°€ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.write(f"- ìµœëŒ€ {max(article_counts)}ê°œì˜ ê¸°ì‚¬ê°€ ë§¤ì¹­ëœ ì¢…ëª©ì´ ìˆìŠµë‹ˆë‹¤.")
            
            # 6. ê²°ê³¼ í‘œì‹œ
            if results:
                st.markdown("### ğŸ“ˆ ë§¤ì¹­ëœ ì¢…ëª© ì •ë³´")
                df_results = pd.DataFrame(results)
                
                # ë°ì´í„° í¬ë§·íŒ…
                df_results['í˜„ì¬ê°€'] = df_results['í˜„ì¬ê°€'].apply(lambda x: f"{x:,}ì›")
                df_results['ë“±ë½ë¥ '] = df_results['ë“±ë½ë¥ '].apply(lambda x: f"{x:.2f}%")
                df_results['ê±°ë˜ëŸ‰'] = df_results['ê±°ë˜ëŸ‰'].apply(lambda x: f"{x:,}")
                df_results['ì‹œê°€ì´ì•¡'] = df_results['ì‹œê°€ì´ì•¡'].apply(lambda x: f"{x/100000000:.0f}ì–µì›")
                
                # ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ
                st.dataframe(
                    df_results,
                    use_container_width=True,
                    hide_index=True
                )
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = df_results.to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"stock_news_{selected_date.strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# secrets í™•ì¸ (ë³´ì•ˆ)
api_available, missing_secrets = check_secrets()

if missing_secrets:
    st.sidebar.warning(f"âš ï¸ ì„¤ì •ë˜ì§€ ì•Šì€ í•­ëª©: {', '.join(missing_secrets)}")
    st.sidebar.info("ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

st.markdown('<h1 class="main-header">ğŸ“° ê²½ì œì  ììœ  í”„ë¡œì íŠ¸ </h1>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ë©”ë‰´
with st.sidebar:
    selected = option_menu(
        menu_title="ë©”ë‰´",
        options=[
            "ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘",
            "ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰",
            "ì˜¤ëŠ˜ì˜ ì¦ì‹œ",
            "ì „ì²´ ì¢…ëª© ì‹œì„¸",
            "íŠ¹ì§•ì£¼ í¬ì°©"
        ],
        icons=[
            "newspaper",
            "search",
            "graph-up",
            "bar-chart",
            "bullseye"  # targetì„ bullseyeë¡œ ë³€ê²½
        ],
        menu_icon="list",
        default_index=0,
        styles={
            "container": {"padding": "0!important", "background-color": "transparent"},
            "icon": {"color": "white", "font-size": "16px"},
            "nav-link": {
                "font-size": "16px",
                "text-align": "left",
                "margin": "0px",
                "padding": "10px",
                "color": "white",
                "background-color": "transparent",
                "border": "none",
                "border-radius": "0px",
            },
            "nav-link-selected": {
                "background-color": "#4CAF50",
                "color": "white",
                "font-weight": "bold",
            },
        }
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“– ì‚¬ìš©ë²•")
    st.markdown("""
    **ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘:**
    1. ì›í•˜ëŠ” ì‹ ë¬¸ì‚¬ ì„ íƒ
    2. ë‚ ì§œ ì„ íƒ
    3. í¬ë¡¤ë§ ì‹œì‘
    4. AI ìš”ì•½ ë³´ê³ ì„œ ì‘ì„±(gemini)
    
    **ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰:**
    1. í‚¤ì›Œë“œ ì…ë ¥
    2. ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì„ íƒ
    3. ê²€ìƒ‰ ì‹œì‘
        
    **ì˜¤ëŠ˜ì˜ ì¦ì‹œ:**
    1. ì£¼ìš” ì§€ìˆ˜ ë™í–¥ 
    2. í™˜ìœ¨ ë° ì›ìì¬ ë™í–¥ 
    3. ê°œë³„ ì¢…ëª© ì°¨íŠ¸ ê²€ìƒ‰ 
    4. ì¢…ëª© ê¸°ìˆ ì  ì§€í‘œ ê²€ìƒ‰
                
    **íŠ¹ì§•ì£¼ í¬ì°©:**
    1. í‚¤ì›Œë“œ ì…ë ¥
    2. ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì„ íƒ
    3. ê²€ìƒ‰ ì‹œì‘
    """)
    
    st.markdown("---")
    st.markdown("### âš™ï¸ ì„¤ì • ì •ë³´")
    
    # API í‚¤ ê°’ì„ ë…¸ì¶œí•˜ì§€ ì•Šê³  ìƒíƒœë§Œ í‘œì‹œ
    api_status = "âœ… ì„¤ì •ë¨" if api_available else "âŒ ë¯¸ì„¤ì •"
    st.info(f"ë„¤ì´ë²„ API: {api_status}")
    
    # ê¸°íƒ€ ì„¤ì • ì •ë³´ (ë¯¼ê°í•˜ì§€ ì•Šì€ ì •ë³´ë§Œ)
    try:
        max_articles = st.secrets["app_settings"]["max_articles_per_request"]
        st.info(f"ìµœëŒ€ ìš”ì²­ ê¸°ì‚¬ ìˆ˜: {max_articles}")
    except:
        st.info("ê¸°ë³¸ ì„¤ì • ì‚¬ìš© ì¤‘")

# ì„ íƒëœ íƒ­ì— ë”°ë¼ í•´ë‹¹ í•¨ìˆ˜ ì‹¤í–‰
if selected == "ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘":
    newspaper_collection_tab()
elif selected == "ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰":
    naver_search_tab()
elif selected == "ì˜¤ëŠ˜ì˜ ì¦ì‹œ":
    display_stock_market_tab()
elif selected == "ì „ì²´ ì¢…ëª© ì‹œì„¸":
    display_stock_data()
elif selected == "íŠ¹ì§•ì£¼ í¬ì°©":
    display_stock_news_tab()