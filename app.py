import streamlit as st
import pandas as pd
from datetime import datetime, timezone, timedelta
import io
import base64
from news_collector import NewsCollector
from naver_search import NaverNewsSearcher
import google.generativeai as genai
from typing import List, Dict
import json
import requests
from bs4 import BeautifulSoup
from stock_market import display_stock_market_tab

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹ ë¬¸ ê¸°ì‚¬ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .category-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #333;
        margin: 1rem 0 0.5rem 0;
        background-color: #f0f2f6;
        padding: 0.5rem;
        border-radius: 5px;
    }
    .article-item {
        background-color: #f8f9fa;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
        border-left: 4px solid #1f77b4;
    }
    .search-box {
        background-color: #e9ecef;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .newspaper-section {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .stButton > button {
        width: 100%;
    }
    .ai-report {
        background-color: #f8f9fa;
        padding: 2rem;
        margin: 1rem 0;
        border-radius: 10px;
        border: 1px solid #e9ecef;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .ai-report h3 {
        color: #1f77b4;
        margin-bottom: 1.5rem;
    }
    .ai-report p {
        line-height: 1.6;
        margin-bottom: 1rem;
    }
    .ai-report ul {
        margin-left: 1.5rem;
        margin-bottom: 1rem;
    }
    .ai-report li {
        margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

def check_secrets():
    """secrets ì„¤ì • í™•ì¸ - í™”ë©´ì— ë…¸ì¶œí•˜ì§€ ì•ŠìŒ"""
    missing_secrets = []
    api_available = False
    
    try:
        client_id = st.secrets["naver_api"]["client_id"]
        client_secret = st.secrets["naver_api"]["client_secret"]
        if client_id and client_secret:
            api_available = True
    except KeyError:
        missing_secrets.append("ë„¤ì´ë²„ API í‚¤")
    
    return api_available, missing_secrets

def remove_duplicates(articles):
    """ì¤‘ë³µ ê¸°ì‚¬ ì œê±°"""
    seen_urls = set()
    unique_articles = []
    
    for article in articles:
        if article['url'] not in seen_urls:
            seen_urls.add(article['url'])
            unique_articles.append(article)
    
    return unique_articles

def create_excel_download(articles):
    """ì—‘ì…€ íŒŒì¼ ìƒì„±"""
    df = pd.DataFrame(articles)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='ì‹ ë¬¸ê¸°ì‚¬')
    return output.getvalue()

def create_text_download(articles, date):
    """í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
    text_content = f"ğŸ“° {date.strftime('%Yë…„ %mì›” %dì¼')}ì˜ ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ\n\n"
    
    newspaper_groups = {}
    for article in articles:
        newspaper = article['newspaper']
        if newspaper not in newspaper_groups:
            newspaper_groups[newspaper] = []
        newspaper_groups[newspaper].append(article)
    
    for newspaper, articles_list in newspaper_groups.items():
        text_content += f"ğŸ“Œ [{newspaper}]\n"
        for article in articles_list:
            page_info = f"[{article['page']}] " if article['page'] else ""
            text_content += f"ğŸ”¹ {page_info}{article['title']}\n   {article['url']}\n"
        text_content += "\n"
    
    return text_content

def create_search_excel_download(articles):
    """ê²€ìƒ‰ ê²°ê³¼ ì—‘ì…€ íŒŒì¼ ìƒì„±"""
    df = pd.DataFrame(articles)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='ê²€ìƒ‰ê²°ê³¼')
    return output.getvalue()

def create_search_csv_download(articles):
    """ê²€ìƒ‰ ê²°ê³¼ CSV íŒŒì¼ ìƒì„±"""
    df = pd.DataFrame(articles)
    return df.to_csv(index=False).encode('utf-8-sig')

def create_search_text_download(articles, keyword):
    """ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
    text_content = f"ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼\n"
    text_content += f"ê²€ìƒ‰ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}\n"
    text_content += f"ì´ {len(articles)}ê°œ ê¸°ì‚¬\n\n"
    
    for i, article in enumerate(articles, 1):
        text_content += f"{i}. {article['title']}\n"
        text_content += f"   ìš”ì•½: {article['description']}\n"
        text_content += f"   ë°œí–‰ì¼: {article['pubDate']}\n"
        text_content += f"   ì¶œì²˜: {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n"
        text_content += f"   ë§í¬: {article['link']}\n\n"
    
    return text_content

def generate_ai_report(articles: List[Dict], date: datetime) -> str:
    """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    try:
        # Google API í‚¤ í™•ì¸
        if 'google_api' not in st.secrets or 'api_key' not in st.secrets['google_api']:
            raise ValueError("Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Gemini API ì„¤ì •
        genai.configure(api_key=st.secrets['google_api']['api_key'])
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # ê¸°ì‚¬ ë°ì´í„° ì¤€ë¹„
        articles_text = []
        for article in articles:
            articles_text.append(f"ì œëª©: {article['title']}\nì‹ ë¬¸ì‚¬: {article['newspaper']}\në§í¬: {article['url']}\n")
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ### ğŸ¯ ì‘ì—… ëª©í‘œ
        ì¡°ê°„ì‹ ë¬¸ì— ê²Œì¬ëœ ê¸°ì‚¬ë“¤ì„ ì¢…í•© ë¶„ì„í•˜ì—¬ ë…ìë“¤ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.

        ### ğŸ“‹ ì…ë ¥ ë°ì´í„°
        - ì¡°ê°„ ì‹ ë¬¸ì— ê²Œì¬ëœ ê¸°ì‚¬ ëª©ë¡
        - ê° ê¸°ì‚¬ì˜ ì œëª©, ì‹ ë¬¸ì‚¬, ë§í¬ ì •ë³´ í¬í•¨

        ### ğŸ—ï¸ ì¶œë ¥ êµ¬ì¡°

        #### 1. ì „ì²´ ê¸€ ì œëª© ì‘ì„±
        - í˜•ì‹: "ğŸ“° [ë‚ ì§œ] ì¡°ê°„ì‹ ë¬¸ ì¢…í•© - [ì£¼ìš” ì´ìŠˆ 2-3ê°œ í‚¤ì›Œë“œ]"
        - ì˜ˆì‹œ: "ğŸ“° 2025ë…„ 5ì›” 28ì¼ ì¡°ê°„ì‹ ë¬¸ ì¢…í•© - ëŒ€ì„  ë§‰íŒ ë„¤ê±°í‹°ë¸Œ ê³µì„¸ì™€ ê²½ì œ íšŒë³µ ì‹ í˜¸"

        #### 2. ì „ì²´ ìš”ì•½ë¬¸ ì‘ì„± (150-200ì)
        - ë‹¹ì¼ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 3-4ê°œë¥¼ í¬í•¨
        - ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, êµ­ì œ ë¶„ì•¼ì˜ ê· í˜• ìˆëŠ” ìš”ì•½
        - ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬

        #### 3. ì„¹ì…˜ë³„ ê¸°ì‚¬ ë¶„ë¥˜ ë° ì‘ì„±

        **ğŸ”¥ ì˜¤ëŠ˜ì˜ Top ì´ìŠˆ (5ê°œ í—¤ë“œë¼ì¸)**
        - ì„ ì • ê¸°ì¤€: 
          * ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ì—ì„œ ê³µí†µìœ¼ë¡œ ë‹¤ë£¬ ê¸°ì‚¬
          * ì‚¬íšŒì  íŒŒê¸‰ë ¥ì´ í° ì‚¬ê±´
          * êµ­ë¯¼ ìƒí™œì— ì§ì ‘ì  ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì´ìŠˆ
        - ê° ê¸°ì‚¬ì˜ ì œëª©ë§Œ ì‘ì„±

        **ğŸ›ï¸ ì •ì¹˜/ì‚¬íšŒ (5ê°œ ê¸°ì‚¬)**
        - ëŒ€ì„ , ì •ì¹˜ì¸ ë™í–¥, ì •ì±… ë°œí‘œ, ì‚¬íšŒ ì´ìŠˆ í¬í•¨
        - ë‚´ë€ ìˆ˜ì‚¬, ì„ ê±° ê´€ë ¨, ì‚¬íšŒ ì œë„ ë³€í™” ë“±

        **ğŸ’° ê²½ì œ/ì‚°ì—… (5ê°œ ê¸°ì‚¬)**
        - ê¸°ì—… ì‹¤ì , ê²½ì œ ì§€í‘œ, ì‚°ì—… ë™í–¥, ê¸ˆìœµ ì •ì±…
        - ìˆ˜ì¶œì…, ì£¼ì‹ì‹œì¥, ë¶€ë™ì‚°, ì†Œë¹„ íŠ¸ë Œë“œ ë“±

        **ğŸ¤– ê¸°ìˆ /AI (5ê°œ ê¸°ì‚¬)**
        - IT, ì¸ê³µì§€ëŠ¥, ì‚¬ì´ë²„ë³´ì•ˆ, í†µì‹ , í˜ì‹  ê¸°ìˆ 
        - ê¸°ì—…ì˜ ê¸°ìˆ  ê°œë°œ, ë””ì§€í„¸ ì „í™˜ ê´€ë ¨
        
        **ğŸŒ êµ­ì œ/ê¸€ë¡œë²Œ (5ê°œ ê¸°ì‚¬)**
        - í•´ì™¸ ì •ì¹˜, êµ­ì œ ê²½ì œ, ì™¸êµ ê´€ê³„
        - ë¯¸êµ­, ì¤‘êµ­, ì¼ë³¸ ë“± ì£¼ìš”êµ­ ë™í–¥

        **ğŸ¤ ì—°ì˜ˆ/ë¬¸í™” (5ê°œ ê¸°ì‚¬)**
        - ì—°ì˜ˆê³„ ì†Œì‹, ë¬¸í™” í–‰ì‚¬, í•œë¥˜, ì˜ˆìˆ  ê´€ë ¨
        - K-ì»¬ì²˜, ì—”í„°í…Œì¸ë¨¼íŠ¸ ì‚°ì—… ë™í–¥

        **ğŸŒï¸ ìŠ¤í¬ì¸  (5ê°œ ê¸°ì‚¬)**
        - í”„ë¡œìŠ¤í¬ì¸ , êµ­ì œëŒ€íšŒ, ì„ ìˆ˜ ë™í–¥
        - ì•¼êµ¬, ì¶•êµ¬, ê³¨í”„ ë“± ì£¼ìš” ìŠ¤í¬ì¸  ì´ìŠˆ
        
        ### ğŸ“ ê° ê¸°ì‚¬ ì‘ì„± í˜•ì‹
        ### [ìˆœë²ˆ]. [ê¸°ì‚¬ ì œëª©]
        **ìš”ì•½**: [í•µì‹¬ ë‚´ìš©ì„ 50ì ì´ë‚´ë¡œ ìš”ì•½]
        **ë§í¬**: [ì›ë¬¸ ë§í¬]
        ### ê°€ë…ì„± ìˆê²Œ ì¤„ë°”ê¿ˆì„ ì´ìš©í•  ê²ƒ.     
        ### ì—¬ëŸ¬ ê¸°ì‚¬ë§í¬ë¥´ í†µí•©í•  ê²½ìš° ì²«ë²ˆì§¸ ê¸°ì‚¬ ë§í¬ë¥¼ ë„£ì–´ì¤„ ê²ƒ.  

        ### ğŸ·ï¸ í•´ì‹œíƒœê·¸ ì‘ì„± (30ê°œ)
        - ì£¼ìš” ì¸ë¬¼ëª…, ê¸°ê´€ëª…, ì´ìŠˆ í‚¤ì›Œë“œ í¬í•¨
        - íŠ¸ë Œë”© ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ìš°ì„  ì„ íƒ
        - ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ë¬¸í™” ë¶„ì•¼ ê· í˜• ìˆê²Œ ë°°ì¹˜
        - í•œê¸€ í•´ì‹œíƒœê·¸ë¡œ ì‘ì„± (#ëŒ€ì„ 2025, #ê²½ì œíšŒë³µ ë“±)

        ### ğŸ¨ ì‘ì„± ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
        - **ê°ê´€ì  í†¤**: íŠ¹ì • ì •ì¹˜ì  ì„±í–¥ ë°°ì œ
        - **ë…ì ì¹œí™”ì **: ì „ë¬¸ ìš©ì–´ ìµœì†Œí™”, ì‰¬ìš´ ì„¤ëª…
        - **ê°„ê²°ì„±**: í•µì‹¬ë§Œ ì¶”ë ¤ì„œ ì „ë‹¬
        - **ê· í˜•ì„±**: ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì´ìŠˆë¥¼ ê³ ë¥´ê²Œ ë‹¤ë£¸
        - **ì‹œì˜ì„±**: ë‹¹ì¼ ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ ìš°ì„  ë°°ì¹˜

        ### ğŸ” ê¸°ì‚¬ ì„ ë³„ ê¸°ì¤€
        1. **ì¤‘ìš”ë„**: ì‚¬íšŒì  íŒŒê¸‰ë ¥ê³¼ ê´€ì‹¬ë„
        2. **ì‹ ë¢°ì„±**: ì£¼ìš” ì–¸ë¡ ì‚¬ ë³´ë„ ì—¬ë¶€
        3. **ë‹¤ì–‘ì„±**: ë¶„ì•¼ë³„ ê· í˜• ìˆëŠ” ì„ íƒ
        4. **ë…ì°½ì„±**: ìƒˆë¡œìš´ ì •ë³´ë‚˜ ê´€ì  ì œê³µ
        5. **ì—°ê´€ì„±**: ë…ìì˜ ì¼ìƒìƒí™œê³¼ì˜ ê´€ë ¨ì„±

        ### âš ï¸ ì£¼ì˜ì‚¬í•­
        - ì‚¬ì‹¤ í™•ì¸ì´ ì–´ë ¤ìš´ ì¶”ì¸¡ì„± ë‚´ìš© ë°°ì œ
        - ê· í˜• ì¡íŒ ì‹œê°ìœ¼ë¡œ ì´ìŠˆ ì „ë‹¬
        - ë§í¬ëŠ” ë°˜ë“œì‹œ ì •í™•í•œ URL ì‚¬ìš©

        ê¸°ì‚¬ ëª©ë¡:
        {json.dumps(articles_text, ensure_ascii=False, indent=2)}
        """
        
        # AI ìš”ì•½ ìƒì„±
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        return f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def create_ai_report_download(articles: List[Dict], date: datetime) -> str:
    """AI ë³´ê³ ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
    report_content = f"ğŸ“Š {date.strftime('%Yë…„ %mì›” %dì¼')} ì‹ ë¬¸ ê¸°ì‚¬ AI ìš”ì•½ ë³´ê³ ì„œ\n\n"
    report_content += generate_ai_report(articles, date)
    return report_content

def newspaper_collection_tab():
    st.markdown("### ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘")
    st.markdown("ì‹ ë¬¸ì— ê²Œì¬ëœ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")
    
    # ë‚ ì§œ ì„ íƒì„ ë§¨ ìœ„ë¡œ ì´ë™
    KST = timezone(timedelta(hours=9))
    current_date = datetime.now(KST).date()
    
    selected_date = st.date_input(
        "ğŸ“… ìˆ˜ì§‘í•  ë‚ ì§œ ì„ íƒ",
        value=current_date,
        max_value=current_date,
        help="ìˆ˜ì§‘í•˜ê³  ì‹¶ì€ ì‹ ë¬¸ ë°œí–‰ì¼ì„ ì„ íƒí•˜ì„¸ìš”",
        key="date_picker"
    )
    
    st.markdown("---")
    
    # ì‹ ë¬¸ì‚¬ ì„ íƒ ì„¹ì…˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown('<div class="category-header">ğŸ“Š ê²½ì œ ì‹ ë¬¸</div>', unsafe_allow_html=True)
        with st.container():
            economic_papers = {
                "ë§¤ì¼ê²½ì œ": "009",
                "ë¨¸ë‹ˆíˆ¬ë°ì´": "008", 
                "ì„œìš¸ê²½ì œ": "011",
                "ì´ë°ì¼ë¦¬": "018",
                "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": "014",
                "í•œêµ­ê²½ì œ": "015"
            }
            
            economic_all = st.checkbox("ì „ì²´ ì„ íƒ", key="economic_all")
            economic_selected = []
            
            for paper, oid in economic_papers.items():
                checked = st.checkbox(paper, value=economic_all, key=f"economic_{oid}")
                if checked:
                    economic_selected.append((paper, oid))
    
    with col2:
        st.markdown('<div class="category-header">ğŸ“‹ ì¢…í•©ì¼ê°„ì§€(ì¡°ê°„)</div>', unsafe_allow_html=True)
        with st.container():
            general_papers = {
                "ê²½í–¥ì‹ ë¬¸": "032",
                "êµ­ë¯¼ì¼ë³´": "005",
                "ë™ì•„ì¼ë³´": "020",
                "ì„œìš¸ì‹ ë¬¸": "081",
                "ì„¸ê³„ì¼ë³´": "022",
                "ì¡°ì„ ì¼ë³´": "023",
                "ì¤‘ì•™ì¼ë³´": "025",
                "í•œê²¨ë ˆ": "028",
                "í•œêµ­ì¼ë³´": "469",
                "ë””ì§€í„¸íƒ€ì„ìŠ¤": "029",
                "ì „ìì‹ ë¬¸": "030"
            }
            
            general_all = st.checkbox("ì „ì²´ ì„ íƒ", key="general_all")
            general_selected = []
            
            for paper, oid in general_papers.items():
                checked = st.checkbox(paper, value=general_all, key=f"general_{oid}")
                if checked:
                    general_selected.append((paper, oid))
    
    with col3:
        st.markdown('<div class="category-header">ğŸŒ† ì„ê°„ ì‹ ë¬¸</div>', unsafe_allow_html=True)
        with st.container():
            evening_papers = {
                "ë¬¸í™”ì¼ë³´": "021",
                "í—¤ëŸ´ë“œê²½ì œ": "016", 
                "ì•„ì‹œì•„ê²½ì œ": "277"
            }
            
            evening_all = st.checkbox("ì „ì²´ ì„ íƒ", key="evening_all")
            evening_selected = []
            
            for paper, oid in evening_papers.items():
                checked = st.checkbox(paper, value=evening_all, key=f"evening_{oid}")
                if checked:
                    evening_selected.append((paper, oid))
    
    st.markdown("---")
    
    # í¬ë¡¤ë§ ì‹œì‘ ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", type="primary", use_container_width=True, key="btn_start_crawling"):
            all_selected = economic_selected + general_selected + evening_selected
            
            if not all_selected:
                st.error("âŒ ìµœì†Œ í•˜ë‚˜ì˜ ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            collector = NewsCollector()
            
            try:
                status_text.text(f"ğŸš€ {len(all_selected)}ê°œ ì‹ ë¬¸ì‚¬ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘...")
                progress_bar.progress(20)
                
                # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¹ ë¥´ê²Œ ìˆ˜ì§‘ (í…Œì´ë¸” í˜•íƒœë¡œ ìƒíƒœ í‘œì‹œ)
                all_articles = collector.crawl_multiple_papers(all_selected, selected_date.strftime("%Y%m%d"))
                
                progress_bar.progress(80)
                
                # ì¤‘ë³µ ì œê±°
                unique_articles = remove_duplicates(all_articles)
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['newspaper_articles'] = unique_articles
                st.session_state['paper_date'] = selected_date
                
                status_text.text(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(unique_articles)}ê°œ ê¸°ì‚¬")
                progress_bar.progress(100)
                
                if len(unique_articles) == 0:
                    st.warning("âš ï¸ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‚ ì§œë‚˜ ì‹ ë¬¸ì‚¬ë¥¼ ì„ íƒí•´ë³´ì„¸ìš”.")
                else:
                    st.success(f"ğŸ‰ {len(all_selected)}ê°œ ì‹ ë¬¸ì‚¬ì—ì„œ ì´ {len(unique_articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                st.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            finally:
                collector.close()
    
    # ê²°ê³¼ í‘œì‹œ
    if 'newspaper_articles' in st.session_state:
        display_newspaper_results()

def display_newspaper_results():
    articles = st.session_state['newspaper_articles']
    
    st.markdown("---")
    
    # ê²°ê³¼ í‘œì‹œ (ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì•„ë˜ë¡œ ì´ë™)
    st.markdown(f"### ğŸ“° {st.session_state['paper_date'].strftime('%Yë…„ %mì›” %dì¼')}ì˜ ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ëª¨ìŒ")
    st.markdown(f"**ì´ {len(articles)}ê°œ ê¸°ì‚¬**")
    
    if len(articles) == 0:
        st.info("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²€ìƒ‰ ê¸°ëŠ¥ (ë²„íŠ¼ ì •ë ¬ ìˆ˜ì •)
    col1, col2, col3 = st.columns([3, 1, 1])

    with col1:
        search_term = st.text_input("ğŸ” ê¸°ì‚¬ ê²€ìƒ‰", placeholder="ì œëª©ìœ¼ë¡œ ê²€ìƒ‰...", key="input_search_articles_newspaper")

    with col2:
        # ë¼ë²¨ì„ ì¶”ê°€í•˜ì—¬ ë†’ì´ ë§ì¶¤
        st.markdown("&nbsp;", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„
        if st.button("ê²€ìƒ‰", key="btn_search_articles_newspaper", use_container_width=True):
            if search_term:
                filtered_articles = [
                    article for article in articles 
                    if search_term.lower() in article['title'].lower()
                ]
                st.session_state['filtered_articles'] = filtered_articles
            else:
                st.session_state['filtered_articles'] = articles

    with col3:
        # ë¼ë²¨ì„ ì¶”ê°€í•˜ì—¬ ë†’ì´ ë§ì¶¤
        st.markdown("&nbsp;", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„
        if st.button("ì´ˆê¸°í™”", key="btn_reset_articles_newspaper", use_container_width=True):
            st.session_state['filtered_articles'] = articles
            st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # í‘œì‹œí•  ê¸°ì‚¬ ê²°ì •
    display_articles = st.session_state.get('filtered_articles', articles)
    
    # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ê²€ìƒ‰ ê¸°ëŠ¥ ì•„ë˜ë¡œ ì´ë™
    st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        excel_data = create_excel_download(display_articles)
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"newspaper_articles_{st.session_state['paper_date'].strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="btn_download_newspaper_excel"
        )
    
    with col2:
        text_data = create_text_download(display_articles, st.session_state['paper_date'])
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=text_data,
            file_name=f"newspaper_articles_{st.session_state['paper_date'].strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_newspaper_text"
        )
    
    with col3:
        if st.button("ğŸ“‹ í´ë¦½ë³´ë“œ ë³µì‚¬", key="btn_copy_newspaper_text"):
            copy_text = create_text_download(display_articles, st.session_state['paper_date'])
            st.code(copy_text, language="text")
            st.success("âœ… í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë³µì‚¬í•˜ì„¸ìš”.")
    
    with col4:
        if st.button("ğŸ¤– AI ë³´ê³ ì„œ ìƒì„±", key="btn_generate_ai_report"):
            with st.spinner("AIê°€ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ê³  ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                report_text = create_ai_report_download(display_articles, st.session_state['paper_date'])
                st.session_state['ai_report'] = report_text
                st.success("âœ… AI ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
    
    st.markdown("---")
    
    # AI ë³´ê³ ì„œê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if 'ai_report' in st.session_state:
        st.markdown("### ğŸ“Š AI ìš”ì•½ ë³´ê³ ì„œ")
        st.markdown(st.session_state['ai_report'])
        st.download_button(
            label="ğŸ“‘ AI ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=st.session_state['ai_report'],
            file_name=f"ai_report_{st.session_state['paper_date'].strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_ai_report"
        )
        st.markdown("---")
    
    # ì‹ ë¬¸ì‚¬ë³„ë¡œ ê·¸ë£¹í™”
    newspaper_groups = {}
    for article in display_articles:
        newspaper = article['newspaper']
        if newspaper not in newspaper_groups:
            newspaper_groups[newspaper] = []
        newspaper_groups[newspaper].append(article)
    
    # ì‹ ë¬¸ì‚¬ë³„ ê¸°ì‚¬ í‘œì‹œ
    for newspaper, articles_list in newspaper_groups.items():
        st.markdown(f"#### ğŸ“Œ [{newspaper}] ({len(articles_list)}ê°œ)")
        for article in articles_list:
            page_info = f"[{article['page']}] " if article['page'] else ""
            st.markdown(f"ğŸ”¹ {page_info}[{article['title']}]({article['url']})")

def naver_search_tab():
    st.markdown("### ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰")
    st.markdown("ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì´ìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        keyword = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="input_search_keyword")
    
    with col2:
        # selectboxë¥¼ number_inputìœ¼ë¡œ ë³€ê²½
        max_articles = st.number_input(
            "ìµœëŒ€ ê¸°ì‚¬ ìˆ˜", 
            min_value=1, 
            max_value=1000, 
            value=100, 
            step=1, 
            key="input_max_articles",
            help="1ë¶€í„° 1000ê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        )
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True, key="btn_start_search"):
            if not keyword:
                st.error("âŒ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            searcher = NaverNewsSearcher()
            
            try:
                status_text.text("ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
                progress_bar.progress(50)
                
                articles = searcher.search_news(keyword, max_articles)
                
                progress_bar.progress(100)
                status_text.text(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! ì´ {len(articles)}ê°œ ê¸°ì‚¬")
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['search_articles'] = articles
                st.session_state['current_search_keyword'] = keyword
                
                if len(articles) == 0:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                else:
                    st.success(f"ğŸ‰ '{keyword}'ì— ëŒ€í•œ {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                progress_bar.progress(0)
                status_text.text("")
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if 'search_articles' in st.session_state:
        display_search_results()

def display_search_results():
    articles = st.session_state['search_articles']
    keyword = st.session_state['current_search_keyword']
    
    st.markdown("---")
    st.markdown(f"### ğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(articles)}ê°œ)")
    
    if len(articles) == 0:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ìƒë‹¨ìœ¼ë¡œ ì´ë™
    st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        excel_data = create_search_excel_download(articles)
        st.download_button(
            label="ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="btn_download_naver_search_excel"
        )
    
    with col2:
        csv_data = create_search_csv_download(articles)
        st.download_button(
            label="ğŸ“Š CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            key="btn_download_naver_search_csv"
        )
    
    with col3:
        text_data = create_search_text_download(articles, keyword)
        st.download_button(
            label="ğŸ“„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=text_data,
            file_name=f"search_results_{keyword}_{datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain",
            key="btn_download_naver_search_text"
        )
    
    st.markdown("---")
    
    # ê²°ê³¼ í‘œì‹œ ì˜µì…˜
    display_mode = st.radio("í‘œì‹œ ë°©ì‹", ["ìš”ì•½ ë³´ê¸°", "ì „ì²´ ë³´ê¸°"], horizontal=True, key="radio_display_mode")
    
    if display_mode == "ìš”ì•½ ë³´ê¸°":
        # ê°„ë‹¨í•œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
        for i, article in enumerate(articles, 1):
            st.markdown(f"**{i}.** [{article['title']}]({article['link']})")
            st.caption(f"ğŸ“… {article['pubDate']} | ğŸ“° {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            if article.get('description'):
                st.write(f"ğŸ’¬ {article['description'][:100]}...")
            st.markdown("---")
    else:
        # ìƒì„¸í•œ expander í˜•íƒœë¡œ í‘œì‹œ
        for i, article in enumerate(articles, 1):
            with st.expander(f"{i}. {article['title']}", expanded=False):
                st.markdown(f"**ìš”ì•½:** {article['description']}")
                st.markdown(f"**ë°œí–‰ì¼:** {article['pubDate']}")
                st.markdown(f"**ì¶œì²˜:** {article.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                st.markdown(f"**ë§í¬:** [ê¸°ì‚¬ ë³´ê¸°]({article['link']})")

# secrets í™•ì¸ (ë³´ì•ˆ)
api_available, missing_secrets = check_secrets()

if missing_secrets:
    st.sidebar.warning(f"âš ï¸ ì„¤ì •ë˜ì§€ ì•Šì€ í•­ëª©: {', '.join(missing_secrets)}")
    st.sidebar.info("ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

st.markdown('<h1 class="main-header">ğŸ“° ì‹ ë¬¸ ê¸°ì‚¬ ìˆ˜ì§‘ê¸°</h1>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”ì— ì„¤ì • ì •ë³´ í‘œì‹œ (ë³´ì•ˆ ì •ë³´ ìˆ¨ê¹€)
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì • ì •ë³´")
    
    # API í‚¤ ê°’ì„ ë…¸ì¶œí•˜ì§€ ì•Šê³  ìƒíƒœë§Œ í‘œì‹œ
    api_status = "âœ… ì„¤ì •ë¨" if api_available else "âŒ ë¯¸ì„¤ì •"
    st.info(f"ë„¤ì´ë²„ API: {api_status}")
    
    # ê¸°íƒ€ ì„¤ì • ì •ë³´ (ë¯¼ê°í•˜ì§€ ì•Šì€ ì •ë³´ë§Œ)
    try:
        max_articles = st.secrets["app_settings"]["max_articles_per_request"]
        st.info(f"ìµœëŒ€ ìš”ì²­ ê¸°ì‚¬ ìˆ˜: {max_articles}")
    except:
        st.info("ê¸°ë³¸ ì„¤ì • ì‚¬ìš© ì¤‘")
    
    st.markdown("---")
    st.markdown("### ğŸ“– ì‚¬ìš©ë²•")
    st.markdown("""
    **ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘:**
    1. ì›í•˜ëŠ” ì‹ ë¬¸ì‚¬ ì„ íƒ
    2. ë‚ ì§œ ì„ íƒ
    3. í¬ë¡¤ë§ ì‹œì‘
    4. AI ìš”ì•½ ë³´ê³ ì„œ ì‘ì„±(gemini)
    
    **ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰:**
    1. í‚¤ì›Œë“œ ì…ë ¥
    2. ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ ì„ íƒ
    3. ê²€ìƒ‰ ì‹œì‘
        
    **ì˜¤ëŠ˜ì˜ ì¦ì‹œ:**
    1. ì˜¤ëŠ˜ì˜ ì¦ì‹œ ë³´ê¸°
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ“Š í†µê³„")
    if 'newspaper_articles' in st.session_state:
        st.metric("ìˆ˜ì§‘ëœ ì‹ ë¬¸ ê¸°ì‚¬", len(st.session_state['newspaper_articles']))
    if 'search_articles' in st.session_state:
        st.metric("ê²€ìƒ‰ëœ ê¸°ì‚¬", len(st.session_state['search_articles']))

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“° ì‹ ë¬¸ ê²Œì¬ ê¸°ì‚¬ ìˆ˜ì§‘", "ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰", "ğŸ“ˆ ì˜¤ëŠ˜ì˜ ì¦ì‹œ"])

with tab1:
    newspaper_collection_tab()

with tab2:
    naver_search_tab()
    
with tab3:
    display_stock_market_tab()